{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AttGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75db773625a54ab3bb793e9e581db847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d13319dcc0b94f8ea2d77b565c0baaf6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e18dbd273884bdeace678124ae5faa5",
              "IPY_MODEL_8cad500f9fc4432db18ad0d2b3cef620"
            ]
          }
        },
        "d13319dcc0b94f8ea2d77b565c0baaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e18dbd273884bdeace678124ae5faa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7bc320485024750bc77f7f654ffb262",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 108857766,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 108857766,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41d101ce5b0b4fcc98ceaff2b06e60f3"
          }
        },
        "8cad500f9fc4432db18ad0d2b3cef620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf666864f3b745ee8d1863e53372d503",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 104M/104M [00:01&lt;00:00, 82.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1224a063bbe746d28c63bd2c2dab4873"
          }
        },
        "a7bc320485024750bc77f7f654ffb262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41d101ce5b0b4fcc98ceaff2b06e60f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf666864f3b745ee8d1863e53372d503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1224a063bbe746d28c63bd2c2dab4873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaumyaGupta-99/Text-to-Image-Using-GANs/blob/main/AttGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wn426F5aMf_"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy.random as random\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDKQL4GFZEml"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i_VoK9RXENG"
      },
      "source": [
        "Mounting the drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybsul0zBgB4V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1a424c77-7b34-498c-eff6-25134a243b65"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQDfcVOroaMx"
      },
      "source": [
        "Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEw73zuHLAog"
      },
      "source": [
        "DATASET_NAME= 'bird'\n",
        "CONFIG_NAME=''\n",
        "DATA_DIR= '/content/gdrive/My Drive/Saumya/birds/birds'\n",
        "GPU_ID=0\n",
        "WORKERS=4\n",
        "B_DCGAN=False\n",
        "B_VALIDATION= False\n",
        "BRANCH_NUM=3\n",
        "RNN_TYPE = 'LSTM'\n",
        "#Train\n",
        "FLAG=False\n",
        "NET_G='/content/gdrive/My Drive/Saumya/output/Model/bird_AttnGAN2.pth'\n",
        "B_NET_D=False\n",
        "BATCH_SIZE=10\n",
        "BASE_SIZE=64\n",
        "NET_E=''\n",
        " \n",
        "DF_DIM=64\n",
        "GF_DIM=32\n",
        "Z_DIM=100\n",
        "R_NUM=2\n",
        " \n",
        "ENCODER_LR = 0.0002\n",
        "DISCRIMINATOR_LR =0.0002\n",
        "GENERATOR_LR =0.0002\n",
        "EMBEDDING_DIM=256\n",
        "CAPTIONS_PER_IMAGE=10\n",
        "WORDS_NUM=18\n",
        "#GF_DIM = 128\n",
        "#DF_DIM=64\n",
        "CONDITION_DIM=100\n",
        "MAX_EPOCH=600\n",
        "SNAPSHOT_INTERVAL=2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF2WvhIIXMrO"
      },
      "source": [
        "Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPkPfvcwbDLz"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        " \n",
        " \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        " \n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy.random as random\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        " \n",
        " \n",
        "def prepare_data(data):\n",
        "    imgs, captions, captions_lens, class_ids, keys = data\n",
        " \n",
        "    # sort data by the length in a decreasing order\n",
        "    sorted_cap_lens, sorted_cap_indices = \\\n",
        "        torch.sort(captions_lens, 0, True)\n",
        " \n",
        "    real_imgs = []\n",
        "    for i in range(len(imgs)):\n",
        "        imgs[i] = imgs[i][sorted_cap_indices]\n",
        "        real_imgs.append(Variable(imgs[i]).cuda())\n",
        " \n",
        "    captions = captions[sorted_cap_indices].squeeze()\n",
        "    class_ids = class_ids[sorted_cap_indices].numpy()\n",
        "    # sent_indices = sent_indices[sorted_cap_indices]\n",
        "    keys = [keys[i] for i in sorted_cap_indices.numpy()]\n",
        "    # print('keys', type(keys), keys[-1])  # list\n",
        "    captions = Variable(captions).cuda()\n",
        "    sorted_cap_lens = Variable(sorted_cap_lens).cuda()\n",
        " \n",
        "    return [real_imgs, captions, sorted_cap_lens,\n",
        "            class_ids, keys]\n",
        " \n",
        " \n",
        "def get_imgs(img_path, imsize, bbox=None,\n",
        "             transform=None, normalize=None):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    width, height = img.size\n",
        "    if bbox is not None:\n",
        "        r = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
        "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
        "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
        "        y1 = np.maximum(0, center_y - r)\n",
        "        y2 = np.minimum(height, center_y + r)\n",
        "        x1 = np.maximum(0, center_x - r)\n",
        "        x2 = np.minimum(width, center_x + r)\n",
        "        img = img.crop([x1, y1, x2, y2])\n",
        " \n",
        "    if transform is not None:\n",
        "        img = transform(img)\n",
        " \n",
        "    ret = []\n",
        " \n",
        "    if B_DCGAN:\n",
        "        ret = [normalize(img)]\n",
        "    else:\n",
        "        for i in range(BRANCH_NUM):\n",
        "            # print(imsize[i])\n",
        "            if i < (BRANCH_NUM - 1):\n",
        "                re_img = transforms.Scale(imsize[i])(img)\n",
        "            else:\n",
        "                re_img = img\n",
        "            ret.append(normalize(re_img))\n",
        " \n",
        "    return ret\n",
        " \n",
        " \n",
        "class TextDataset(data.Dataset):\n",
        "    def __init__(self, data_dir, split='train',\n",
        "                 base_size=64,\n",
        "                 transform=None, target_transform=None):\n",
        " \n",
        "        \n",
        " \n",
        "        self.transform = transform\n",
        "        self.norm = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        self.target_transform = target_transform\n",
        " \n",
        "        self.embeddings_num = CAPTIONS_PER_IMAGE\n",
        "        self.imsize = []\n",
        "        for i in range(BRANCH_NUM):\n",
        "            self.imsize.append(base_size)\n",
        "            base_size = base_size * 2\n",
        " \n",
        "        self.data = []\n",
        "        self.data_dir = data_dir\n",
        "        if data_dir.find('birds') != -1:\n",
        "            self.bbox = self.load_bbox()\n",
        "        else:\n",
        "            self.bbox = None\n",
        "        split_dir = os.path.join(data_dir, split)\n",
        " \n",
        "        self.filenames, self.captions, self.ixtoword, \\\n",
        "            self.wordtoix, self.n_words = self.load_text_data(data_dir, split)\n",
        " \n",
        "        self.class_id = self.load_class_id(split_dir, len(self.filenames))\n",
        "        self.number_example = len(self.filenames)\n",
        " \n",
        "    def load_bbox(self):\n",
        "        data_dir = self.data_dir\n",
        "        bbox_path = '/content/gdrive/My Drive/Saumya/bounding_boxes.txt'\n",
        "        df_bounding_boxes = pd.read_csv(bbox_path,\n",
        "                                        delim_whitespace=True,\n",
        "                                        header=None).astype(int)\n",
        "        #\n",
        "        filepath = '/content/gdrive/My Drive/Saumya/images.txt'\n",
        "        df_filenames = \\\n",
        "            pd.read_csv(filepath, delim_whitespace=True, header=None)\n",
        "        filenames = df_filenames[1].tolist()\n",
        "        print('Total filenames: ', len(filenames), filenames[0])\n",
        "        #\n",
        "        filename_bbox = {img_file[:-4]: [] for img_file in filenames}\n",
        "        numImgs = len(filenames)\n",
        "        for i in range(0, numImgs):\n",
        "            # bbox to= [x-left, y-top, width, height]\n",
        "            bbox = df_bounding_boxes.iloc[i][1:].tolist()\n",
        " \n",
        "            key = filenames[i][:-4]\n",
        "            filename_bbox[key] = bbox\n",
        "        \n",
        "        return filename_bbox\n",
        " \n",
        "    def load_captions(self, data_dir, filenames):\n",
        "        all_captions = []\n",
        "        for i in range(len(filenames)):\n",
        "            cap_path = '%s/text/%s.txt' % (data_dir, filenames[i])\n",
        "            with open(cap_path, \"r\") as f:\n",
        "                captions = f.read().decode('utf8').split('\\n')\n",
        "                cnt = 0\n",
        "                for cap in captions:\n",
        "                    if len(cap) == 0:\n",
        "                        continue\n",
        "                    cap = cap.replace(\"\\ufffd\\ufffd\", \" \")\n",
        "                    # picks out sequences of alphanumeric characters as tokens\n",
        "                    # and drops everything else\n",
        "                    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "                    tokens = tokenizer.tokenize(cap.lower())\n",
        "                    # print('tokens', tokens)\n",
        "                    if len(tokens) == 0:\n",
        "                        print('cap', cap)\n",
        "                        continue\n",
        " \n",
        "                    tokens_new = []\n",
        "                    for t in tokens:\n",
        "                        t = t.encode('ascii', 'ignore').decode('ascii')\n",
        "                        if len(t) > 0:\n",
        "                            tokens_new.append(t)\n",
        "                    all_captions.append(tokens_new)\n",
        "                    cnt += 1\n",
        "                    if cnt == self.embeddings_num:\n",
        "                        break\n",
        "                if cnt < self.embeddings_num:\n",
        "                    print('ERROR: the captions for %s less than %d'\n",
        "                          % (filenames[i], cnt))\n",
        "        return all_captions\n",
        " \n",
        "    def build_dictionary(self, train_captions, test_captions):\n",
        "        word_counts = defaultdict(float)\n",
        "        captions = train_captions + test_captions\n",
        "        for sent in captions:\n",
        "            for word in sent:\n",
        "                word_counts[word] += 1\n",
        " \n",
        "        vocab = [w for w in word_counts if word_counts[w] >= 0]\n",
        " \n",
        "        ixtoword = {}\n",
        "        ixtoword[0] = '<end>'\n",
        "        wordtoix = {}\n",
        "        wordtoix['<end>'] = 0\n",
        "        ix = 1\n",
        "        for w in vocab:\n",
        "            wordtoix[w] = ix\n",
        "            ixtoword[ix] = w\n",
        "            ix += 1\n",
        " \n",
        "        train_captions_new = []\n",
        "        for t in train_captions:\n",
        "            rev = []\n",
        "            for w in t:\n",
        "                if w in wordtoix:\n",
        "                    rev.append(wordtoix[w])\n",
        "            # rev.append(0)  # do not need '<end>' token\n",
        "            train_captions_new.append(rev)\n",
        " \n",
        "        test_captions_new = []\n",
        "        for t in test_captions:\n",
        "            rev = []\n",
        "            for w in t:\n",
        "                if w in wordtoix:\n",
        "                    rev.append(wordtoix[w])\n",
        "            # rev.append(0)  # do not need '<end>' token\n",
        "            test_captions_new.append(rev)\n",
        " \n",
        "        return [train_captions_new, test_captions_new,\n",
        "                ixtoword, wordtoix, len(ixtoword)]\n",
        " \n",
        "    def load_text_data(self, data_dir, split):\n",
        "        filepath = os.path.join(data_dir, 'captions.pickle')\n",
        "        train_names = self.load_filenames(data_dir, 'train')\n",
        "        test_names = self.load_filenames(data_dir, 'test')\n",
        "        if not os.path.isfile(filepath):\n",
        "            train_captions = self.load_captions(data_dir, train_names)\n",
        "            test_captions = self.load_captions(data_dir, test_names)\n",
        " \n",
        "            train_captions, test_captions, ixtoword, wordtoix, n_words = \\\n",
        "                self.build_dictionary(train_captions, test_captions)\n",
        "            with open(filepath, 'wb') as f:\n",
        "                pickle.dump([train_captions, test_captions,\n",
        "                             ixtoword, wordtoix], f, protocol=2)\n",
        "                print('Save to: ', filepath)\n",
        "        else:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                x = pickle.load(f,encoding='latin1')\n",
        "                train_captions, test_captions = x[0], x[1]\n",
        "                ixtoword, wordtoix = x[2], x[3]\n",
        "                del x\n",
        "                n_words = len(ixtoword)\n",
        "                print('Load from: ', filepath)\n",
        "        if split == 'train':\n",
        "            # a list of list: each list contains\n",
        "            # the indices of words in a sentence\n",
        "            captions = train_captions\n",
        "            filenames = train_names\n",
        "        else:  # split=='test'\n",
        "            captions = test_captions\n",
        "            filenames = test_names\n",
        "        return filenames, captions, ixtoword, wordtoix, n_words\n",
        " \n",
        "    def load_class_id(self, data_dir, total_num):\n",
        "        if os.path.isfile(data_dir + '/class_info.pickle'):\n",
        "            with open(data_dir + '/class_info.pickle', 'rb') as f:\n",
        "                class_id = pickle.load(f,encoding='latin1')\n",
        "        else:\n",
        "            class_id = np.arange(total_num)\n",
        "        return class_id\n",
        " \n",
        "    def load_filenames(self, data_dir, split):\n",
        "        filepath = '%s/%s/filenames.pickle' % (data_dir, split)\n",
        "        if os.path.isfile(filepath):\n",
        "            with open(filepath, 'rb') as f:\n",
        "                filenames = pickle.load(f,encoding='latin1')\n",
        "            print('Load filenames from: %s (%d)' % (filepath, len(filenames)))\n",
        "        else:\n",
        "            filenames = []\n",
        "        return filenames\n",
        " \n",
        "    def get_caption(self, sent_ix):\n",
        "        # a list of indices for a sentence\n",
        "        sent_caption = np.asarray(self.captions[sent_ix]).astype('int64')\n",
        "        if (sent_caption == 0).sum() > 0:\n",
        "            print('ERROR: do not need END (0) token', sent_caption)\n",
        "        num_words = len(sent_caption)\n",
        "        x = np.zeros((WORDS_NUM, 1), dtype='int64')\n",
        "        x_len = num_words\n",
        "        if num_words <= WORDS_NUM:\n",
        "            x[:num_words, 0] = sent_caption\n",
        "        else:\n",
        "            ix = list(np.arange(num_words))  # 1, 2, 3,..., maxNum\n",
        "            np.random.shuffle(ix)\n",
        "            ix = ix[:WORDS_NUM]\n",
        "            ix = np.sort(ix)\n",
        "            x[:, 0] = sent_caption[ix]\n",
        "            x_len = WORDS_NUM\n",
        "        return x, x_len\n",
        " \n",
        "    def __getitem__(self, index):\n",
        "        #\n",
        "        key = self.filenames[index]\n",
        "        cls_id = self.class_id[index]\n",
        "        #\n",
        "        if self.bbox is not None:\n",
        "            bbox = self.bbox[key]\n",
        "        else:\n",
        "            bbox = None\n",
        "            # data_dir = self.data_dir\n",
        "        #\n",
        "        img_name = '%s/images/%s.jpg' % ('/content/gdrive/My Drive/Saumya', key)\n",
        "        imgs = get_imgs(img_name, self.imsize,\n",
        "                        bbox, self.transform, normalize=self.norm)\n",
        "        # random select a sentence\n",
        "        sent_ix = random.randint(0, self.embeddings_num)\n",
        "        new_sent_ix = index * self.embeddings_num + sent_ix\n",
        "        caps, cap_len = self.get_caption(new_sent_ix)\n",
        "        return imgs, caps, cap_len, cls_id, key\n",
        "    \n",
        "    def get_mis_caption(self, cls_id):\n",
        "        mis_match_captions_t = []\n",
        "        mis_match_captions = torch.zeros(99,WORDS_NUM)\n",
        "        mis_match_captions_len = torch.zeros(99)\n",
        "        i = 0\n",
        "        while len(mis_match_captions_t) < 99:\n",
        "            idx = random.randint(0, self.number_example-1)\n",
        "            if cls_id == self.class_id[idx]:\n",
        "                continue\n",
        "            sent_ix = random.randint(0, self.embeddings_num-1)\n",
        "            new_sent_ix = idx * self.embeddings_num + sent_ix\n",
        "            caps_t, cap_len_t = self.get_caption(new_sent_ix)\n",
        "            mis_match_captions_t.append(torch.from_numpy(caps_t).squeeze())\n",
        "            mis_match_captions_len[i] = cap_len_t\n",
        "            i = i +1\n",
        "        sorted_cap_lens, sorted_cap_indices = torch.sort(mis_match_captions_len, 0, True)\n",
        "        for i in range(99):\n",
        "            mis_match_captions[i,:] = mis_match_captions_t[sorted_cap_indices[i]]\n",
        "        return mis_match_captions.type(torch.LongTensor).cuda(), sorted_cap_lens.type(torch.LongTensor).cuda()\n",
        " \n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCcy37GcXcjl"
      },
      "source": [
        "Generator and Discriminator models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6_jWKyaq97D"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        " \n",
        "def conv1x1(in_planes, out_planes):\n",
        "    \"1x1 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n",
        "                     padding=0, bias=False)\n",
        " \n",
        " \n",
        "def func_attention(query, context, gamma1):\n",
        "    \"\"\"\n",
        "    query: batch x ndf x queryL\n",
        "    context: batch x ndf x ih x iw (sourceL=ihxiw)\n",
        "    mask: batch_size x sourceL\n",
        "    \"\"\"\n",
        "    batch_size, queryL = query.size(0), query.size(2)\n",
        "    ih, iw = context.size(2), context.size(3)\n",
        "    sourceL = ih * iw\n",
        " \n",
        "    # --> batch x sourceL x ndf\n",
        "    context = context.view(batch_size, -1, sourceL)\n",
        "    contextT = torch.transpose(context, 1, 2).contiguous()\n",
        " \n",
        "    # Get attention\n",
        "    # (batch x sourceL x ndf)(batch x ndf x queryL)\n",
        "    # -->batch x sourceL x queryL\n",
        "    attn = torch.bmm(contextT, query) # Eq. (7) in AttnGAN paper\n",
        "    # --> batch*sourceL x queryL\n",
        "    attn = attn.view(batch_size*sourceL, queryL)\n",
        "    attn = nn.Softmax()(attn)  # Eq. (8)\n",
        " \n",
        "    # --> batch x sourceL x queryL\n",
        "    attn = attn.view(batch_size, sourceL, queryL)\n",
        "    # --> batch*queryL x sourceL\n",
        "    attn = torch.transpose(attn, 1, 2).contiguous()\n",
        "    attn = attn.view(batch_size*queryL, sourceL)\n",
        "    #  Eq. (9)\n",
        "    attn = attn * gamma1\n",
        "    attn = nn.Softmax()(attn)\n",
        "    attn = attn.view(batch_size, queryL, sourceL)\n",
        "    # --> batch x sourceL x queryL\n",
        "    attnT = torch.transpose(attn, 1, 2).contiguous()\n",
        " \n",
        "    # (batch x ndf x sourceL)(batch x sourceL x queryL)\n",
        "    # --> batch x ndf x queryL\n",
        "    weightedContext = torch.bmm(context, attnT)\n",
        " \n",
        "    return weightedContext, attn.view(batch_size, -1, ih, iw)\n",
        " \n",
        " \n",
        "class GlobalAttentionGeneral(nn.Module):\n",
        "    def __init__(self, idf, cdf):\n",
        "        super(GlobalAttentionGeneral, self).__init__()\n",
        "        self.conv_context = conv1x1(cdf, idf)\n",
        "        self.sm = nn.Softmax()\n",
        "        self.mask = None\n",
        " \n",
        "    def applyMask(self, mask):\n",
        "        self.mask = mask  # batch x sourceL\n",
        " \n",
        "    def forward(self, input, context):\n",
        "        \"\"\"\n",
        "            input: batch x idf x ih x iw (queryL=ihxiw)\n",
        "            context: batch x cdf x sourceL\n",
        "        \"\"\"\n",
        "        ih, iw = input.size(2), input.size(3)\n",
        "        queryL = ih * iw\n",
        "        batch_size, sourceL = context.size(0), context.size(2)\n",
        " \n",
        "        # --> batch x queryL x idf\n",
        "        target = input.view(batch_size, -1, queryL)\n",
        "        targetT = torch.transpose(target, 1, 2).contiguous()\n",
        "        # batch x cdf x sourceL --> batch x cdf x sourceL x 1\n",
        "        sourceT = context.unsqueeze(3)\n",
        "        # --> batch x idf x sourceL\n",
        "        sourceT = self.conv_context(sourceT).squeeze(3)\n",
        " \n",
        "        # Get attention\n",
        "        # (batch x queryL x idf)(batch x idf x sourceL)\n",
        "        # -->batch x queryL x sourceL\n",
        "        attn = torch.bmm(targetT, sourceT)\n",
        "        # --> batch*queryL x sourceL\n",
        "        attn = attn.view(batch_size*queryL, sourceL)\n",
        "        if self.mask is not None:\n",
        "            # batch_size x sourceL --> batch_size*queryL x sourceL\n",
        "            mask = self.mask.repeat(queryL, 1)\n",
        "            attn.data.masked_fill_(mask.data, -float('inf'))\n",
        "        attn = self.sm(attn)  # Eq. (2)\n",
        "        # --> batch x queryL x sourceL\n",
        "        attn = attn.view(batch_size, queryL, sourceL)\n",
        "        # --> batch x sourceL x queryL\n",
        "        attn = torch.transpose(attn, 1, 2).contiguous()\n",
        " \n",
        "        # (batch x idf x sourceL)(batch x sourceL x queryL)\n",
        "        # --> batch x idf x queryL\n",
        "        weightedContext = torch.bmm(sourceT, attn)\n",
        "        weightedContext = weightedContext.view(batch_size, -1, ih, iw)\n",
        "        attn = attn.view(batch_size, -1, ih, iw)\n",
        " \n",
        "        return weightedContext, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvxlwI1iX4fL"
      },
      "source": [
        "Models (RNN_ENCODER and CNN_ENCODER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbnR3LLWo7qt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "class GLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GLU, self).__init__()\n",
        " \n",
        "    def forward(self, x):\n",
        "        nc = x.size(1)\n",
        "        assert nc % 2 == 0, 'channels dont divide 2!'\n",
        "        nc = int(nc/2)\n",
        "        return x[:, :nc] * F.sigmoid(x[:, nc:])\n",
        " \n",
        " \n",
        "def conv1x1(in_planes, out_planes, bias=False):\n",
        "    \"1x1 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1,\n",
        "                     padding=0, bias=bias)\n",
        " \n",
        " \n",
        "def conv3x3(in_planes, out_planes):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
        "                     padding=1, bias=False)\n",
        " \n",
        " \n",
        "# Upsale the spatial size by a factor of 2\n",
        "def upBlock(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "        conv3x3(in_planes, out_planes * 2),\n",
        "        nn.BatchNorm2d(out_planes * 2),\n",
        "        GLU())\n",
        "    return block\n",
        " \n",
        " \n",
        "# Keep the spatial size\n",
        "def Block3x3_relu(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        conv3x3(in_planes, out_planes * 2),\n",
        "        nn.BatchNorm2d(out_planes * 2),\n",
        "        GLU())\n",
        "    return block\n",
        " \n",
        " \n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, channel_num):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            conv3x3(channel_num, channel_num * 2),\n",
        "            nn.BatchNorm2d(channel_num * 2),\n",
        "            GLU(),\n",
        "            conv3x3(channel_num, channel_num),\n",
        "            nn.BatchNorm2d(channel_num))\n",
        " \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.block(x)\n",
        "        out += residual\n",
        "        return out\n",
        " \n",
        " \n",
        "# ############## Text2Image Encoder-Decoder #######\n",
        "class RNN_ENCODER(nn.Module):\n",
        "    def __init__(self, ntoken, ninput=300, drop_prob=0.5,\n",
        "                 nhidden=128, nlayers=1, bidirectional=True):\n",
        "        super(RNN_ENCODER, self).__init__()\n",
        "        WORDS_NUM = 18\n",
        "        self.n_steps = WORDS_NUM\n",
        "        self.ntoken = ntoken  # size of the dictionary\n",
        "        self.ninput = ninput  # size of each embedding vector\n",
        "        self.drop_prob = drop_prob # probability of an element to be zeroed\n",
        "        self.nlayers = nlayers  # Number of recurrent layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.rnn_type = RNN_TYPE\n",
        "        if bidirectional:\n",
        "            self.num_directions = 2\n",
        "        else:\n",
        "            self.num_directions = 1\n",
        "        # number of features in the hidden state\n",
        "        self.nhidden = nhidden // self.num_directions\n",
        " \n",
        "        self.define_module()\n",
        "        self.init_weights()\n",
        " \n",
        "    def define_module(self):\n",
        "        self.encoder = nn.Embedding(self.ntoken, self.ninput)\n",
        "        self.drop = nn.Dropout(self.drop_prob)\n",
        "        # dropout: If non-zero, introduces a dropout layer on\n",
        "        # the outputs of each RNN layer except the last layer\n",
        "        self.rnn = nn.LSTM(self.ninput, self.nhidden,\n",
        "                            self.nlayers, batch_first=True,\n",
        "                            dropout=self.drop_prob,\n",
        "                            bidirectional=self.bidirectional)\n",
        " \n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        " \n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters()).data\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (Variable(weight.new(self.nlayers * self.num_directions,\n",
        "                                        bsz, self.nhidden).zero_()),\n",
        "                    Variable(weight.new(self.nlayers * self.num_directions,\n",
        "                                        bsz, self.nhidden).zero_()))\n",
        "        else:\n",
        "            return Variable(weight.new(self.nlayers * self.num_directions,\n",
        "                                       bsz, self.nhidden).zero_())\n",
        " \n",
        "    def forward(self, captions, cap_lens, hidden, mask=None):\n",
        "        # input: torch.LongTensor of size batch x n_steps\n",
        "        # --> emb: batch x n_steps x ninput\n",
        "        emb = self.drop(self.encoder(captions))\n",
        "        #\n",
        "        # Returns: a PackedSequence object\n",
        "        cap_lens = cap_lens.data.tolist()\n",
        "        emb = pack_padded_sequence(emb, cap_lens, batch_first=True)\n",
        "        # #hidden and memory (num_layers * num_directions, batch, hidden_size):\n",
        "        # tensor containing the initial hidden state for each element in batch.\n",
        "        # #output (batch, seq_len, hidden_size * num_directions)\n",
        "        # #or a PackedSequence object:\n",
        "        # tensor containing output features (h_t) from the last layer of RNN\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        # PackedSequence object\n",
        "        # --> (batch, seq_len, hidden_size * num_directions)\n",
        "        output = pad_packed_sequence(output, batch_first=True)[0]\n",
        "        # output = self.drop(output)\n",
        "        # --> batch x hidden_size*num_directions x seq_len\n",
        "        words_emb = output.transpose(1, 2)\n",
        "        # --> batch x num_directions*hidden_size\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            sent_emb = hidden[0].transpose(0, 1).contiguous()\n",
        "        else:\n",
        "            sent_emb = hidden.transpose(0, 1).contiguous()\n",
        "        sent_emb = sent_emb.view(-1, self.nhidden * self.num_directions)\n",
        "        return words_emb, sent_emb\n",
        " \n",
        " \n",
        "class CNN_ENCODER(nn.Module):\n",
        "    def __init__(self, nef):\n",
        "        super(CNN_ENCODER, self).__init__()\n",
        "        self.nef = nef\n",
        " \n",
        "        model = models.inception_v3()\n",
        "        url = 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n",
        "        model.load_state_dict(model_zoo.load_url(url))\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        print('Load pretrained model from ', url)\n",
        "        # print(model)\n",
        " \n",
        "        self.define_module(model)\n",
        "        self.init_trainable_weights()\n",
        " \n",
        "    def define_module(self, model):\n",
        "        self.Conv2d_1a_3x3 = model.Conv2d_1a_3x3\n",
        "        self.Conv2d_2a_3x3 = model.Conv2d_2a_3x3\n",
        "        self.Conv2d_2b_3x3 = model.Conv2d_2b_3x3\n",
        "        self.Conv2d_3b_1x1 = model.Conv2d_3b_1x1\n",
        "        self.Conv2d_4a_3x3 = model.Conv2d_4a_3x3\n",
        "        self.Mixed_5b = model.Mixed_5b\n",
        "        self.Mixed_5c = model.Mixed_5c\n",
        "        self.Mixed_5d = model.Mixed_5d\n",
        "        self.Mixed_6a = model.Mixed_6a\n",
        "        self.Mixed_6b = model.Mixed_6b\n",
        "        self.Mixed_6c = model.Mixed_6c\n",
        "        self.Mixed_6d = model.Mixed_6d\n",
        "        self.Mixed_6e = model.Mixed_6e\n",
        "        self.Mixed_7a = model.Mixed_7a\n",
        "        self.Mixed_7b = model.Mixed_7b\n",
        "        self.Mixed_7c = model.Mixed_7c\n",
        " \n",
        "        self.emb_features = conv1x1(768, self.nef)\n",
        "        self.emb_cnn_code = nn.Linear(2048, self.nef)\n",
        " \n",
        "    def init_trainable_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.emb_features.weight.data.uniform_(-initrange, initrange)\n",
        "        self.emb_cnn_code.weight.data.uniform_(-initrange, initrange)\n",
        " \n",
        "    def forward(self, x):\n",
        "        features = None\n",
        "        # --> fixed-size input: batch x 3 x 299 x 299\n",
        "        x = nn.Upsample(size=(299, 299), mode='bilinear')(x)\n",
        "        # 299 x 299 x 3\n",
        "        x = self.Conv2d_1a_3x3(x)\n",
        "        # 149 x 149 x 32\n",
        "        x = self.Conv2d_2a_3x3(x)\n",
        "        # 147 x 147 x 32\n",
        "        x = self.Conv2d_2b_3x3(x)\n",
        "        # 147 x 147 x 64\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        # 73 x 73 x 64\n",
        "        x = self.Conv2d_3b_1x1(x)\n",
        "        # 73 x 73 x 80\n",
        "        x = self.Conv2d_4a_3x3(x)\n",
        "        # 71 x 71 x 192\n",
        " \n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        # 35 x 35 x 192\n",
        "        x = self.Mixed_5b(x)\n",
        "        # 35 x 35 x 256\n",
        "        x = self.Mixed_5c(x)\n",
        "        # 35 x 35 x 288\n",
        "        x = self.Mixed_5d(x)\n",
        "        # 35 x 35 x 288\n",
        " \n",
        "        x = self.Mixed_6a(x)\n",
        "        # 17 x 17 x 768\n",
        "        x = self.Mixed_6b(x)\n",
        "        # 17 x 17 x 768\n",
        "        x = self.Mixed_6c(x)\n",
        "        # 17 x 17 x 768\n",
        "        x = self.Mixed_6d(x)\n",
        "        # 17 x 17 x 768\n",
        "        x = self.Mixed_6e(x)\n",
        "        # 17 x 17 x 768\n",
        " \n",
        "        # image region features\n",
        "        features = x\n",
        "        # 17 x 17 x 768\n",
        " \n",
        "        x = self.Mixed_7a(x)\n",
        "        # 8 x 8 x 1280\n",
        "        x = self.Mixed_7b(x)\n",
        "        # 8 x 8 x 2048\n",
        "        x = self.Mixed_7c(x)\n",
        "        # 8 x 8 x 2048\n",
        "        x = F.avg_pool2d(x, kernel_size=8)\n",
        "        # 1 x 1 x 2048\n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        # 1 x 1 x 2048\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # 2048\n",
        " \n",
        "        # global image features\n",
        "        cnn_code = self.emb_cnn_code(x)\n",
        "        # 512\n",
        "        if features is not None:\n",
        "            features = self.emb_features(features)\n",
        "        return features, cnn_code\n",
        " \n",
        " \n",
        "# ############## G networks ###################\n",
        "class CA_NET(nn.Module):\n",
        "    # some code is modified from vae examples\n",
        "    # (https://github.com/pytorch/examples/blob/master/vae/main.py)\n",
        "    def __init__(self):\n",
        "        super(CA_NET, self).__init__()\n",
        "        self.t_dim = EMBEDDING_DIM\n",
        "        self.c_dim = CONDITION_DIM\n",
        "        self.fc = nn.Linear(self.t_dim, self.c_dim * 4, bias=True)\n",
        "        self.relu = GLU()\n",
        " \n",
        "    def encode(self, text_embedding):\n",
        "        x = self.relu(self.fc(text_embedding))\n",
        "        mu = x[:, :self.c_dim]\n",
        "        logvar = x[:, self.c_dim:]\n",
        "        return mu, logvar\n",
        " \n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        " \n",
        "    def forward(self, text_embedding):\n",
        "        mu, logvar = self.encode(text_embedding)\n",
        "        c_code = self.reparametrize(mu, logvar)\n",
        "        return c_code, mu, logvar\n",
        " \n",
        " \n",
        "class INIT_STAGE_G(nn.Module):\n",
        "    def __init__(self, ngf, ncf):\n",
        "        super(INIT_STAGE_G, self).__init__()\n",
        "        self.gf_dim = ngf\n",
        "        Z_DIM = 100\n",
        "        self.in_dim =Z_DIM+ncf  # EMBEDDING_DIM\n",
        "        self.define_module()\n",
        " \n",
        "    def define_module(self):\n",
        "        nz, ngf = self.in_dim, self.gf_dim\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(nz, ngf * 4 * 4 * 2, bias=False),\n",
        "            nn.BatchNorm1d(ngf * 4 * 4 * 2),\n",
        "            GLU())\n",
        " \n",
        "        self.upsample1 = upBlock(ngf, ngf // 2)\n",
        "        self.upsample2 = upBlock(ngf // 2, ngf // 4)\n",
        "        self.upsample3 = upBlock(ngf // 4, ngf // 8)\n",
        "        self.upsample4 = upBlock(ngf // 8, ngf // 16)\n",
        " \n",
        "    def forward(self, z_code, c_code):\n",
        "        \"\"\"\n",
        "        :param z_code: batch xZ_DIM\n",
        "        :param c_code: batch x EMBEDDING_DIM\n",
        "        :return: batch x ngf/16 x 64 x 64\n",
        "        \"\"\"\n",
        "        c_z_code = torch.cat((c_code, z_code), 1)\n",
        "        # state size ngf x 4 x 4\n",
        "        out_code = self.fc(c_z_code)\n",
        "        out_code = out_code.view(-1, self.gf_dim, 4, 4)\n",
        "        # state size ngf/3 x 8 x 8\n",
        "        out_code = self.upsample1(out_code)\n",
        "        # state size ngf/4 x 16 x 16\n",
        "        out_code = self.upsample2(out_code)\n",
        "        # state size ngf/8 x 32 x 32\n",
        "        out_code32 = self.upsample3(out_code)\n",
        "        # state size ngf/16 x 64 x 64\n",
        "        out_code64 = self.upsample4(out_code32)\n",
        " \n",
        "        return out_code64\n",
        " \n",
        " \n",
        "class NEXT_STAGE_G(nn.Module):\n",
        "    def __init__(self, ngf, nef, ncf):\n",
        "        super(NEXT_STAGE_G, self).__init__()\n",
        "        self.gf_dim = ngf\n",
        "        self.ef_dim = nef\n",
        "        self.cf_dim = ncf\n",
        "        R_NUM=2\n",
        "        self.num_residual =R_N JoUM\n",
        "        self.define_module()\n",
        " \n",
        "    def _make_layer(self, block, channel_num):\n",
        "        layers = []\n",
        "        R_NUM = 2\n",
        "        for i in range(R_NUM):\n",
        "            layers.append(block(channel_num))\n",
        "        return nn.Sequential(*layers)\n",
        " \n",
        "    def define_module(self):\n",
        "        ngf = self.gf_dim\n",
        "        self.att = GlobalAttentionGeneral(ngf, self.ef_dim)\n",
        "        self.residual = self._make_layer(ResBlock, ngf * 2)\n",
        "        self.upsample = upBlock(ngf * 2, ngf)\n",
        " \n",
        "    def forward(self, h_code, c_code, word_embs, mask):\n",
        "        \"\"\"\n",
        "            h_code1(query):  batch x idf x ih x iw (queryL=ihxiw)\n",
        "            word_embs(context): batch x cdf x sourceL (sourceL=seq_len)\n",
        "            c_code1: batch x idf x queryL\n",
        "            att1: batch x sourceL x queryL\n",
        "        \"\"\"\n",
        "        self.att.applyMask(mask)\n",
        "        c_code, att = self.att(h_code, word_embs)\n",
        "        h_c_code = torch.cat((h_code, c_code), 1)\n",
        "        out_code = self.residual(h_c_code)\n",
        " \n",
        "        # state size ngf/2 x 2in_size x 2in_size\n",
        "        out_code = self.upsample(out_code)\n",
        " \n",
        "        return out_code, att\n",
        " \n",
        " \n",
        "class GET_IMAGE_G(nn.Module):\n",
        "    def __init__(self, ngf):\n",
        "        super(GET_IMAGE_G, self).__init__()\n",
        "        self.gf_dim = ngf\n",
        "        self.img = nn.Sequential(\n",
        "            conv3x3(ngf, 3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        " \n",
        "    def forward(self, h_code):\n",
        "        out_img = self.img(h_code)\n",
        "        return out_img\n",
        " \n",
        " \n",
        "class G_NET(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(G_NET, self).__init__()\n",
        "        ngf = GF_DIM\n",
        "        nef = EMBEDDING_DIM\n",
        "        ncf = CONDITION_DIM\n",
        "        self.ca_net = CA_NET()\n",
        " \n",
        "        if BRANCH_NUM > 0:\n",
        "            self.h_net1 = INIT_STAGE_G(ngf * 16, ncf)\n",
        "            self.img_net1 = GET_IMAGE_G(ngf)\n",
        "        # gf x 64 x 64\n",
        "        if BRANCH_NUM > 1:\n",
        "            self.h_net2 = NEXT_STAGE_G(ngf, nef, ncf)\n",
        "            self.img_net2 = GET_IMAGE_G(ngf)\n",
        "        if BRANCH_NUM > 2:\n",
        "            self.h_net3 = NEXT_STAGE_G(ngf, nef, ncf)\n",
        "            self.img_net3 = GET_IMAGE_G(ngf)\n",
        " \n",
        "    def forward(self, z_code, sent_emb, word_embs, mask):\n",
        "        \"\"\"\n",
        "            :param z_code: batch x Z_DIM\n",
        "            :param sent_emb: batch xTEXT.EMBEDDING_DIM\n",
        "            :param word_embs: batch x cdf x seq_len\n",
        "            :param mask: batch x seq_len\n",
        "            :return:\n",
        "        \"\"\"\n",
        "        fake_imgs = []\n",
        "        att_maps = []\n",
        "        c_code, mu, logvar = self.ca_net(sent_emb)\n",
        "        if BRANCH_NUM > 0:\n",
        "            h_code1 = self.h_net1(z_code, c_code)\n",
        "            fake_img1 = self.img_net1(h_code1)\n",
        "            fake_imgs.append(fake_img1)\n",
        "        if BRANCH_NUM > 1:\n",
        "            h_code2, att1 = \\\n",
        "                self.h_net2(h_code1, c_code, word_embs, mask)\n",
        "            fake_img2 = self.img_net2(h_code2)\n",
        "            fake_imgs.append(fake_img2)\n",
        "            if att1 is not None:\n",
        "                att_maps.append(att1)\n",
        "        if BRANCH_NUM > 2:\n",
        "            h_code3, att2 = \\\n",
        "                self.h_net3(h_code2, c_code, word_embs, mask)\n",
        "            fake_img3 = self.img_net3(h_code3)\n",
        "            fake_imgs.append(fake_img3)\n",
        "            if att2 is not None:\n",
        "                att_maps.append(att2)\n",
        " \n",
        "        return fake_imgs, att_maps, mu, logvar\n",
        " \n",
        " \n",
        " \n",
        "class G_DCGAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(G_DCGAN, self).__init__()\n",
        "        ngf = GF_DIM\n",
        "        nef = EMBEDDING_DIM\n",
        "        ncf = CONDITION_DIM\n",
        "        self.ca_net = CA_NET()\n",
        "        # 16gf x 64 x 64 --> gf x 64 x 64 --> 3 x 64 x 64\n",
        "        if BRANCH_NUM > 0:\n",
        "          self.h_net1 = INIT_STAGE_G(ngf * 16, ncf)\n",
        "        # gf x 64 x 64\n",
        "        if BRANCH_NUM > 1:\n",
        "            self.h_net2 = NEXT_STAGE_G(ngf, nef, ncf)\n",
        "        if BRANCH_NUM > 2:\n",
        "            self.h_net3 = NEXT_STAGE_G(ngf, nef, ncf)\n",
        "        self.img_net = GET_IMAGE_G(ngf)\n",
        " \n",
        "    def forward(self, z_code, sent_emb, word_embs, mask):\n",
        "        \"\"\"\n",
        "            :param z_code: batch x Z_DIM\n",
        "            :param sent_emb: batch x EMBEDDING_DIM\n",
        "            :param word_embs: batch x cdf x seq_len\n",
        "            :param mask: batch x seq_len\n",
        "            :return:\n",
        "        \"\"\"\n",
        "        c_code, mu, logvar = self.ca_net(sent_emb)\n",
        "        if BRANCH_NUM > 0:\n",
        "            h_code = self.h_net1(z_code, c_code)\n",
        "        if BRANCH_NUM > 1:\n",
        "            h_code, att1 = self.h_net2(h_code, c_code, word_embs, mask)\n",
        "            if att1 is not None:\n",
        "                att_maps.append(att1)\n",
        "        if BRANCH_NUM > 2:\n",
        "            h_code, att2 = self.h_net3(h_code, c_code, word_embs, mask)\n",
        "            if att2 is not None:\n",
        "                att_maps.append(att2)\n",
        " \n",
        "        fake_imgs = self.img_net(h_code)\n",
        "        return [fake_imgs], att_maps, mu, logvar\n",
        " \n",
        " \n",
        "# ############## D networks ##########################\n",
        "def Block3x3_leakRelu(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        conv3x3(in_planes, out_planes),\n",
        "        nn.BatchNorm2d(out_planes),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "    return block\n",
        " \n",
        " \n",
        "# Downsale the spatial size by a factor of 2\n",
        "def downBlock(in_planes, out_planes):\n",
        "    block = nn.Sequential(\n",
        "        nn.Conv2d(in_planes, out_planes, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(out_planes),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "    return block\n",
        " \n",
        " \n",
        "# Downsale the spatial size by a factor of 16\n",
        "def encode_image_by_16times(ndf):\n",
        "    encode_img = nn.Sequential(\n",
        "        # --> state size. ndf x in_size/2 x in_size/2\n",
        "        nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # --> state size 2ndf x x in_size/4 x in_size/4\n",
        "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(ndf * 2),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # --> state size 4ndf x in_size/8 x in_size/8\n",
        "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(ndf * 4),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        # --> state size 8ndf x in_size/16 x in_size/16\n",
        "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(ndf * 8),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "    return encode_img\n",
        " \n",
        " \n",
        "class D_GET_LOGITS(nn.Module):\n",
        "    def __init__(self, ndf, nef, bcondition=False):\n",
        "        super(D_GET_LOGITS, self).__init__()\n",
        "        self.df_dim = ndf\n",
        "        self.ef_dim = nef\n",
        "        self.bcondition = bcondition\n",
        "        if self.bcondition:\n",
        "            self.jointConv = Block3x3_leakRelu(ndf * 8 + nef, ndf * 8)\n",
        " \n",
        "        self.outlogits = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=4),\n",
        "            nn.Sigmoid())\n",
        " \n",
        "    def forward(self, h_code, c_code=None):\n",
        "        if self.bcondition and c_code is not None:\n",
        "            # conditioning output\n",
        "            c_code = c_code.view(-1, self.ef_dim, 1, 1)\n",
        "            c_code = c_code.repeat(1, 1, 4, 4)\n",
        "            # state size (ngf+egf) x 4 x 4\n",
        "            h_c_code = torch.cat((h_code, c_code), 1)\n",
        "            # state size ngf x in_size x in_size\n",
        "            h_c_code = self.jointConv(h_c_code)\n",
        "        else:\n",
        "            h_c_code = h_code\n",
        " \n",
        "        output = self.outlogits(h_c_code)\n",
        "        return output.view(-1)\n",
        " \n",
        " \n",
        "# For 64 x 64 images\n",
        "class D_NET64(nn.Module):\n",
        "    def __init__(self, b_jcu=True):\n",
        "        super(D_NET64, self).__init__()\n",
        "        ndf = DF_DIM\n",
        "        nef = EMBEDDING_DIM\n",
        "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
        "        if b_jcu:\n",
        "            self.UNCOND_DNET = D_GET_LOGITS(ndf, nef, bcondition=False)\n",
        "        else:\n",
        "            self.UNCOND_DNET = None\n",
        "        self.COND_DNET = D_GET_LOGITS(ndf, nef, bcondition=True)\n",
        " \n",
        "    def forward(self, x_var):\n",
        "        x_code4 = self.img_code_s16(x_var)  # 4 x 4 x 8df\n",
        "        return x_code4\n",
        " \n",
        " \n",
        "# For 128 x 128 images\n",
        "class D_NET128(nn.Module):\n",
        "    def __init__(self, b_jcu=True):\n",
        "        super(D_NET128, self).__init__()\n",
        "        ndf =DF_DIM\n",
        "        nef =EMBEDDING_DIM\n",
        "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
        "        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n",
        "        self.img_code_s32_1 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n",
        "        #\n",
        "        if b_jcu:\n",
        "            self.UNCOND_DNET = D_GET_LOGITS(ndf, nef, bcondition=False)\n",
        "        else:\n",
        "            self.UNCOND_DNET = None\n",
        "        self.COND_DNET = D_GET_LOGITS(ndf, nef, bcondition=True)\n",
        " \n",
        "    def forward(self, x_var):\n",
        "        x_code8 = self.img_code_s16(x_var)   # 8 x 8 x 8df\n",
        "        x_code4 = self.img_code_s32(x_code8)   # 4 x 4 x 16df\n",
        "        x_code4 = self.img_code_s32_1(x_code4)  # 4 x 4 x 8df\n",
        "        return x_code4\n",
        " \n",
        " \n",
        "# For 256 x 256 images\n",
        "class D_NET256(nn.Module):\n",
        "    def __init__(self, b_jcu=True):\n",
        "        super(D_NET256, self).__init__()\n",
        "        ndf = DF_DIM\n",
        "        nef = EMBEDDING_DIM\n",
        "        self.img_code_s16 = encode_image_by_16times(ndf)\n",
        "        self.img_code_s32 = downBlock(ndf * 8, ndf * 16)\n",
        "        self.img_code_s64 = downBlock(ndf * 16, ndf * 32)\n",
        "        self.img_code_s64_1 = Block3x3_leakRelu(ndf * 32, ndf * 16)\n",
        "        self.img_code_s64_2 = Block3x3_leakRelu(ndf * 16, ndf * 8)\n",
        "        if b_jcu:\n",
        "            self.UNCOND_DNET = D_GET_LOGITS(ndf, nef, bcondition=False)\n",
        "        else:\n",
        "            self.UNCOND_DNET = None\n",
        "        self.COND_DNET = D_GET_LOGITS(ndf, nef, bcondition=True)\n",
        " \n",
        "    def forward(self, x_var):\n",
        "        x_code16 = self.img_code_s16(x_var)\n",
        "        x_code8 = self.img_code_s32(x_code16)\n",
        "        x_code4 = self.img_code_s64(x_code8)\n",
        "        x_code4 = self.img_code_s64_1(x_code4)\n",
        "        x_code4 = self.img_code_s64_2(x_code4)\n",
        "        return x_code4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKIK318XX8lP"
      },
      "source": [
        "Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6FlKWz60on6"
      },
      "source": [
        "#loss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "#from GlobalAttention import func_attention\n",
        "# ##################Loss for matching text-image###################\n",
        "GAMMA1 = 5.0\n",
        "GAMMA3 = 10.0\n",
        "GAMMA2 = 5.0\n",
        "LAMBDA = 1.0\n",
        "def cosine_similarity(x1, x2, dim=1, eps=1e-8):\n",
        "    \"\"\"Returns cosine similarity between x1 and x2, computed along dim.\n",
        "    \"\"\"\n",
        "    w12 = torch.sum(x1 * x2, dim)\n",
        "    w1 = torch.norm(x1, 2, dim)\n",
        "    w2 = torch.norm(x2, 2, dim)\n",
        "    return (w12 / (w1 * w2).clamp(min=eps)).squeeze()\n",
        " \n",
        " \n",
        "def sent_loss(cnn_code, rnn_code, labels, class_ids,\n",
        "              batch_size, eps=1e-8):\n",
        "    # ### Mask mis-match samples  ###\n",
        "    # that come from the same class as the real sample ###\n",
        "    masks = []\n",
        "    if class_ids is not None:\n",
        "        for i in range(batch_size):\n",
        "            mask = (class_ids == class_ids[i]).astype(np.uint8)\n",
        "            mask[i] = 0\n",
        "            masks.append(mask.reshape((1, -1)))\n",
        "        masks = np.concatenate(masks, 0)\n",
        "        # masks: batch_size x batch_size\n",
        "        masks = torch.ByteTensor(masks)\n",
        "        masks = masks.cuda()\n",
        " \n",
        "    # --> seq_len x batch_size x nef\n",
        "    if cnn_code.dim() == 2:\n",
        "        cnn_code = cnn_code.unsqueeze(0)\n",
        "        rnn_code = rnn_code.unsqueeze(0)\n",
        "    # cnn_code_norm / rnn_code_norm: seq_len x batch_size x 1\n",
        "    cnn_code_norm = torch.norm(cnn_code, 2, dim=2, keepdim=True)\n",
        "    rnn_code_norm = torch.norm(rnn_code, 2, dim=2, keepdim=True)\n",
        "    # scores* / norm*: seq_len x batch_size x batch_size\n",
        "    scores0 = torch.bmm(cnn_code, rnn_code.transpose(1, 2))\n",
        "    norm0 = torch.bmm(cnn_code_norm, rnn_code_norm.transpose(1, 2))\n",
        "    scores0 = scores0 / norm0.clamp(min=eps) * GAMMA3\n",
        " \n",
        "    # --> batch_size x batch_size\n",
        "    scores0 = scores0.squeeze()\n",
        "    if class_ids is not None:\n",
        "        scores0.data.masked_fill_(masks, -float('inf'))\n",
        "    scores1 = scores0.transpose(0, 1)\n",
        "    if labels is not None:\n",
        "        loss0 = nn.CrossEntropyLoss()(scores0, labels)\n",
        "        loss1 = nn.CrossEntropyLoss()(scores1, labels)\n",
        "    else:\n",
        "        loss0, loss1 = None, None\n",
        "    return loss0, loss1\n",
        " \n",
        " \n",
        "def words_loss(img_features, words_emb, labels,\n",
        "               cap_lens, class_ids, batch_size):\n",
        "    \"\"\"\n",
        "        words_emb(query): batch x nef x seq_len\n",
        "        img_features(context): batch x nef x 17 x 17\n",
        "    \"\"\"\n",
        "    masks = []\n",
        "    att_maps = []\n",
        "    similarities = []\n",
        "    cap_lens = cap_lens.data.tolist()\n",
        "    for i in range(batch_size):\n",
        "        if class_ids is not None:\n",
        "            mask = (class_ids == class_ids[i]).astype(np.uint8)\n",
        "            mask[i] = 0\n",
        "            masks.append(mask.reshape((1, -1)))\n",
        "        # Get the i-th text description\n",
        "        words_num = cap_lens[i]\n",
        "        # -> 1 x nef x words_num\n",
        "        word = words_emb[i, :, :words_num].unsqueeze(0).contiguous()\n",
        "        # -> batch_size x nef x words_num\n",
        "        word = word.repeat(batch_size, 1, 1)\n",
        "        # batch x nef x 17*17\n",
        "        context = img_features\n",
        "        \"\"\"\n",
        "            word(query): batch x nef x words_num\n",
        "            context: batch x nef x 17 x 17\n",
        "            weiContext: batch x nef x words_num\n",
        "            attn: batch x words_num x 17 x 17\n",
        "        \"\"\"\n",
        "        weiContext, attn = func_attention(word, context,GAMMA1)\n",
        "        att_maps.append(attn[i].unsqueeze(0).contiguous())\n",
        "        # --> batch_size x words_num x nef\n",
        "        word = word.transpose(1, 2).contiguous()\n",
        "        weiContext = weiContext.transpose(1, 2).contiguous()\n",
        "        # --> batch_size*words_num x nef\n",
        "        word = word.view(batch_size * words_num, -1)\n",
        "        weiContext = weiContext.view(batch_size * words_num, -1)\n",
        "        #\n",
        "        # -->batch_size*words_num\n",
        "        row_sim = cosine_similarity(word, weiContext)\n",
        "        # --> batch_size x words_num\n",
        "        row_sim = row_sim.view(batch_size, words_num)\n",
        " \n",
        "        # Eq. (10)\n",
        "        row_sim.mul_(GAMMA2).exp_()\n",
        "        row_sim = row_sim.sum(dim=1, keepdim=True)\n",
        "        row_sim = torch.log(row_sim)\n",
        " \n",
        "        # --> 1 x batch_size\n",
        "        # similarities(i, j): the similarity between the i-th image and the j-th text description\n",
        "        similarities.append(row_sim)\n",
        " \n",
        "    # batch_size x batch_size\n",
        "    similarities = torch.cat(similarities, 1)\n",
        "    if class_ids is not None:\n",
        "        masks = np.concatenate(masks, 0)\n",
        "        # masks: batch_size x batch_size\n",
        "        masks = torch.ByteTensor(masks)\n",
        "        masks = masks.cuda()\n",
        " \n",
        "    similarities = similarities * GAMMA3\n",
        "    if class_ids is not None:\n",
        "        similarities.data.masked_fill_(masks, -float('inf'))\n",
        "    similarities1 = similarities.transpose(0, 1)\n",
        "    if labels is not None:\n",
        "        loss0 = nn.CrossEntropyLoss()(similarities, labels)\n",
        "        loss1 = nn.CrossEntropyLoss()(similarities1, labels)\n",
        "    else:\n",
        "        loss0, loss1 = None, None\n",
        "    return loss0, loss1, att_maps\n",
        " \n",
        " \n",
        "# ##################Loss for G and Ds##############################\n",
        "def discriminator_loss(netD, real_imgs, fake_imgs, conditions,\n",
        "                       real_labels, fake_labels):\n",
        "    # Forward\n",
        "    real_features = netD(real_imgs)\n",
        "    fake_features = netD(fake_imgs.detach())\n",
        "    # loss\n",
        "    #\n",
        "    cond_real_logits = netD.COND_DNET(real_features, conditions)\n",
        "    cond_real_errD = nn.BCELoss()(cond_real_logits, real_labels)\n",
        "    cond_fake_logits = netD.COND_DNET(fake_features, conditions)\n",
        "    cond_fake_errD = nn.BCELoss()(cond_fake_logits, fake_labels)\n",
        "    #\n",
        "    batch_size = real_features.size(0)\n",
        "    cond_wrong_logits = netD.COND_DNET(real_features[:(batch_size - 1)], conditions[1:batch_size])\n",
        "    cond_wrong_errD = nn.BCELoss()(cond_wrong_logits, fake_labels[1:batch_size])\n",
        " \n",
        "    if netD.UNCOND_DNET is not None:\n",
        "        real_logits = netD.UNCOND_DNET(real_features)\n",
        "        fake_logits = netD.UNCOND_DNET(fake_features)\n",
        "        real_errD = nn.BCELoss()(real_logits, real_labels)\n",
        "        fake_errD = nn.BCELoss()(fake_logits, fake_labels)\n",
        "        errD = ((real_errD + cond_real_errD) / 2. +\n",
        "                (fake_errD + cond_fake_errD + cond_wrong_errD) / 3.)\n",
        "    else:\n",
        "        errD = cond_real_errD + (cond_fake_errD + cond_wrong_errD) / 2.\n",
        "    return Variable(errD,requires_grad=True)\n",
        " \n",
        " \n",
        "def generator_loss(netsD, image_encoder, fake_imgs, real_labels,\n",
        "                   words_embs, sent_emb, match_labels,\n",
        "                   cap_lens, class_ids):\n",
        "    numDs = len(netsD)\n",
        "    batch_size = real_labels.size(0)\n",
        "    logs = ''\n",
        "    # Forward\n",
        "    errG_total = 0\n",
        "    for i in range(numDs):\n",
        "        features = netsD[i](fake_imgs[i])\n",
        "        cond_logits = netsD[i].COND_DNET(features, sent_emb)\n",
        "        cond_errG = nn.BCELoss()(cond_logits, real_labels)\n",
        "        if netsD[i].UNCOND_DNET is  not None:\n",
        "            logits = netsD[i].UNCOND_DNET(features)\n",
        "            errG = nn.BCELoss()(logits, real_labels)\n",
        "            g_loss = errG + cond_errG\n",
        "        else:\n",
        "            g_loss = cond_errG\n",
        "        errG_total += g_loss\n",
        "        # err_img = errG_total\n",
        "        logs += 'g_loss%d: %.2f ' % (i, g_loss)\n",
        " \n",
        "        # Ranking loss\n",
        "        if i == (numDs - 1):\n",
        "            # words_features: batch_size x nef x 17 x 17\n",
        "            # sent_code: batch_size x nef\n",
        "            region_features, cnn_code = image_encoder(fake_imgs[i])\n",
        "            w_loss0, w_loss1, _ = words_loss(region_features, words_embs,\n",
        "                                             match_labels, cap_lens,\n",
        "                                             class_ids, batch_size)\n",
        "            w_loss = (w_loss0 + w_loss1) * \\\n",
        "                LAMBDA\n",
        "            # err_words = err_words + w_loss\n",
        " \n",
        "            s_loss0, s_loss1 = sent_loss(cnn_code, sent_emb,\n",
        "                                         match_labels, class_ids, batch_size)\n",
        "            s_loss = (s_loss0 + s_loss1) * \\\n",
        "                LAMBDA\n",
        "            # err_sent = err_sent + s_loss\n",
        " \n",
        "            errG_total += w_loss + s_loss\n",
        "            logs += 'w_loss: %.2f s_loss: %.2f ' % (w_loss, s_loss)\n",
        "    return errG_total, logs\n",
        " \n",
        " \n",
        "##################################################################\n",
        "def KL_loss(mu, logvar):\n",
        "    # -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.mean(KLD_element).mul_(-0.5)\n",
        "    return KLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjYghn5tn9lW"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import pprint\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN1CTSr7YAt8"
      },
      "source": [
        "OTHER IMPORTANT FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QROIW9Zby5A4"
      },
      "source": [
        "import os\n",
        "import errno\n",
        "import numpy as np\n",
        "from torch.nn import init\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        " \n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from copy import deepcopy\n",
        "import skimage.transform\n",
        "from copy import deepcopy\n",
        "import skimage.transform\n",
        "# For visualization ################################################\n",
        "COLOR_DIC = {0:[128,64,128],  1:[244, 35,232],\n",
        "             2:[70, 70, 70],  3:[102,102,156],\n",
        "             4:[190,153,153], 5:[153,153,153],\n",
        "             6:[250,170, 30], 7:[220, 220, 0],\n",
        "             8:[107,142, 35], 9:[152,251,152],\n",
        "             10:[70,130,180], 11:[220,20, 60],\n",
        "             12:[255, 0, 0],  13:[0, 0, 142],\n",
        "             14:[119,11, 32], 15:[0, 60,100],\n",
        "             16:[0, 80, 100], 17:[0, 0, 230],\n",
        "             18:[0,  0, 70],  19:[0, 0,  0]}\n",
        "FONT_MAX = 50\n",
        " \n",
        " \n",
        "def drawCaption(convas, captions, ixtoword, vis_size, off1=2, off2=2):\n",
        "    num = captions.size(0)\n",
        "    img_txt = Image.fromarray(convas)\n",
        "    # get a font\n",
        "    # fnt = None  # ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 50)\n",
        "    fnt = ImageFont.truetype(\"/content/gdrive/My Drive/Saumya/Chn_Prop_Arial_Normal.ttf\",25)\n",
        "    # # get a drawing context\n",
        "    d = ImageDraw.Draw(img_txt)\n",
        "    \n",
        " \n",
        "    sentence_list = []\n",
        "    for i in range(num):\n",
        "        cap = captions[i].data.cpu().numpy()\n",
        "        sentence = []\n",
        "        for j in range(len(cap)):\n",
        "            if cap[j] == 0:\n",
        "                break\n",
        "            word = ixtoword[cap[j]].encode('ascii', 'ignore').decode('ascii')\n",
        "            d.text(((j + off1) * (vis_size + off2), i * FONT_MAX), '%d:%s' % (j, word[:6]),\n",
        "                   font=fnt, fill=(255, 255, 255, 255))\n",
        "            sentence.append(word)\n",
        "        sentence_list.append(sentence)\n",
        "    return img_txt, sentence_list\n",
        "\n",
        "def mkdir_p(path):\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError as exc:  # Python >2.5\n",
        "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
        "            pass\n",
        "        else:\n",
        "            raise\n",
        " \n",
        " \n",
        " \n",
        "def _merge_a_into_b(a, b):\n",
        "    \"\"\"Merge config dictionary a into config dictionary b, clobbering the\n",
        "    options in b whenever they are also specified in a.\n",
        "    \"\"\"\n",
        "    if type(a) is not edict:\n",
        "        return\n",
        " \n",
        "    for k, v in a.iteritems():\n",
        "        # a must specify keys that are in b\n",
        "        if not b.has_key(k):\n",
        "            raise KeyError('{} is not a valid config key'.format(k))\n",
        " \n",
        "        # the types must match, too\n",
        "        old_type = type(b[k])\n",
        "        if old_type is not type(v):\n",
        "            if isinstance(b[k], np.ndarray):\n",
        "                v = np.array(v, dtype=b[k].dtype)\n",
        "            else:\n",
        "                raise ValueError(('Type mismatch ({} vs. {}) '\n",
        "                                  'for config key: {}').format(type(b[k]),\n",
        "                                                               type(v), k))\n",
        " \n",
        "        # recursively merge dicts\n",
        "        if type(v) is edict:\n",
        "            try:\n",
        "                _merge_a_into_b(a[k], b[k])\n",
        "            except:\n",
        "                print('Error under config key: {}'.format(k))\n",
        "                raise\n",
        "        else:\n",
        "            b[k] = v\n",
        " \n",
        " \n",
        "def cfg_from_file(filename):\n",
        "    \"\"\"Load a config file and merge it into the default options.\"\"\"\n",
        "    import yaml\n",
        "    with open(filename, 'r') as f:\n",
        "        yaml_cfg = edict(yaml.load(f))\n",
        " \n",
        "    _merge_a_into_b(yaml_cfg, __C)\n",
        " \n",
        " \n",
        " \n",
        "####################################################################\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.orthogonal(m.weight.data, 1.0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.orthogonal(m.weight.data, 1.0)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.fill_(0.0)\n",
        " \n",
        "def build_super_images(real_imgs, captions, ixtoword,\n",
        "                       attn_maps, att_sze, lr_imgs=None,\n",
        "                       batch_size=BATCH_SIZE,\n",
        "                       max_word_num=WORDS_NUM):\n",
        "    nvis = 8\n",
        "    real_imgs = real_imgs[:nvis]\n",
        "    if lr_imgs is not None:\n",
        "        lr_imgs = lr_imgs[:nvis]\n",
        "    if att_sze == 17:\n",
        "        vis_size = att_sze * 16\n",
        "    else:\n",
        "        vis_size = real_imgs.size(2)\n",
        "\n",
        "    text_convas = \\\n",
        "        np.ones([batch_size * FONT_MAX,\n",
        "                 (max_word_num + 2) * (vis_size + 2), 3],\n",
        "                dtype=np.uint8)\n",
        "\n",
        "    for i in range(max_word_num):\n",
        "        istart = (i + 2) * (vis_size + 2)\n",
        "        iend = (i + 3) * (vis_size + 2)\n",
        "        text_convas[:, istart:iend, :] = COLOR_DIC[i]\n",
        "\n",
        "\n",
        "    real_imgs = \\\n",
        "        nn.functional.interpolate(real_imgs,size=(vis_size, vis_size),\n",
        "                                  mode='bilinear', align_corners=False)\n",
        "    # [-1, 1] --> [0, 1]\n",
        "    real_imgs.add_(1).div_(2).mul_(255)\n",
        "    real_imgs = real_imgs.data.numpy()\n",
        "    # b x c x h x w --> b x h x w x c\n",
        "    real_imgs = np.transpose(real_imgs, (0, 2, 3, 1))\n",
        "    pad_sze = real_imgs.shape\n",
        "    middle_pad = np.zeros([pad_sze[2], 2, 3])\n",
        "    post_pad = np.zeros([pad_sze[1], pad_sze[2], 3])\n",
        "    if lr_imgs is not None:\n",
        "        lr_imgs = \\\n",
        "            nn.functional.interpolate(lr_imgs,size=(vis_size, vis_size),\n",
        "                                  mode='bilinear', align_corners=False)\n",
        "        # [-1, 1] --> [0, 1]\n",
        "        lr_imgs.add_(1).div_(2).mul_(255)\n",
        "        lr_imgs = lr_imgs.data.numpy()\n",
        "        # b x c x h x w --> b x h x w x c\n",
        "        lr_imgs = np.transpose(lr_imgs, (0, 2, 3, 1))\n",
        "\n",
        "    # batch x seq_len x 17 x 17 --> batch x 1 x 17 x 17\n",
        "    seq_len = max_word_num\n",
        "    img_set = []\n",
        "    num = nvis  # len(attn_maps)\n",
        "\n",
        "    text_map, sentences = \\\n",
        "        drawCaption(text_convas, captions, ixtoword, vis_size)\n",
        "    text_map = np.asarray(text_map).astype(np.uint8)\n",
        "\n",
        "    bUpdate = 1\n",
        "    for i in range(num):\n",
        "        attn = attn_maps[i].cpu().view(1, -1, att_sze, att_sze)\n",
        "        # --> 1 x 1 x 17 x 17\n",
        "        attn_max = attn.max(dim=1, keepdim=True)\n",
        "        attn = torch.cat([attn_max[0], attn], 1)\n",
        "        #\n",
        "        attn = attn.view(-1, 1, att_sze, att_sze)\n",
        "        attn = attn.repeat(1, 3, 1, 1).data.numpy()\n",
        "        # n x c x h x w --> n x h x w x c\n",
        "        attn = np.transpose(attn, (0, 2, 3, 1))\n",
        "        num_attn = attn.shape[0]\n",
        "        #\n",
        "        img = real_imgs[i]\n",
        "        if lr_imgs is None:\n",
        "            lrI = img\n",
        "        else:\n",
        "            lrI = lr_imgs[i]\n",
        "        row = [lrI, middle_pad]\n",
        "        row_merge = [img, middle_pad]\n",
        "        row_beforeNorm = []\n",
        "        minVglobal, maxVglobal = 1, 0\n",
        "        for j in range(num_attn):\n",
        "            one_map = attn[j]\n",
        "            if (vis_size // att_sze) > 1:\n",
        "                one_map = \\\n",
        "                    skimage.transform.pyramid_expand(one_map, sigma=20,\n",
        "                                                     upscale=vis_size // att_sze,\n",
        "                                                     multichannel=True)\n",
        "            row_beforeNorm.append(one_map)\n",
        "            minV = one_map.min()\n",
        "            maxV = one_map.max()\n",
        "            if minVglobal > minV:\n",
        "                minVglobal = minV\n",
        "            if maxVglobal < maxV:\n",
        "                maxVglobal = maxV\n",
        "        for j in range(seq_len + 1):\n",
        "            if j < num_attn:\n",
        "                one_map = row_beforeNorm[j]\n",
        "                one_map = (one_map - minVglobal) / (maxVglobal - minVglobal)\n",
        "                one_map *= 255\n",
        "                #\n",
        "                PIL_im = Image.fromarray(np.uint8(img))\n",
        "                PIL_att = Image.fromarray(np.uint8(one_map))\n",
        "                merged = \\\n",
        "                    Image.new('RGBA', (vis_size, vis_size), (0, 0, 0, 0))\n",
        "                mask = Image.new('L', (vis_size, vis_size), (210))\n",
        "                merged.paste(PIL_im, (0, 0))\n",
        "                merged.paste(PIL_att, (0, 0), mask)\n",
        "                merged = np.array(merged)[:, :, :3]\n",
        "            else:\n",
        "                one_map = post_pad\n",
        "                merged = post_pad\n",
        "            row.append(one_map)\n",
        "            row.append(middle_pad)\n",
        "            #\n",
        "            row_merge.append(merged)\n",
        "            row_merge.append(middle_pad)\n",
        "        row = np.concatenate(row, 1)\n",
        "        row_merge = np.concatenate(row_merge, 1)\n",
        "        txt = text_map[i * FONT_MAX: (i + 1) * FONT_MAX]\n",
        "        if txt.shape[1] != row.shape[1]:\n",
        "            print('txt', txt.shape, 'row', row.shape)\n",
        "            bUpdate = 0\n",
        "            break\n",
        "        row = np.concatenate([txt, row, row_merge], 0)\n",
        "        img_set.append(row)\n",
        "    if bUpdate:\n",
        "        img_set = np.concatenate(img_set, 0)\n",
        "        img_set = img_set.astype(np.uint8)\n",
        "        return img_set, sentences\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def build_super_images2(real_imgs, captions, cap_lens, ixtoword,\n",
        "                        attn_maps, att_sze, vis_size=256, topK=5):\n",
        "    batch_size = real_imgs.size(0)\n",
        "    max_word_num = np.max(cap_lens)\n",
        "    text_convas = np.ones([batch_size * FONT_MAX,\n",
        "                           max_word_num * (vis_size + 2), 3],\n",
        "                           dtype=np.uint8)\n",
        "\n",
        "    real_imgs = \\\n",
        "        nn.functional.interpolate(real_imgs,size=(vis_size, vis_size),\n",
        "                                    mode='bilinear', align_corners=False)\n",
        "    # [-1, 1] --> [0, 1]\n",
        "    real_imgs.add_(1).div_(2).mul_(255)\n",
        "    real_imgs = real_imgs.data.numpy()\n",
        "    # b x c x h x w --> b x h x w x c\n",
        "    real_imgs = np.transpose(real_imgs, (0, 2, 3, 1))\n",
        "    pad_sze = real_imgs.shape\n",
        "    middle_pad = np.zeros([pad_sze[2], 2, 3])\n",
        "\n",
        "    # batch x seq_len x 17 x 17 --> batch x 1 x 17 x 17\n",
        "    img_set = []\n",
        "    num = len(attn_maps)\n",
        "\n",
        "    text_map, sentences = \\\n",
        "        drawCaption(text_convas, captions, ixtoword, vis_size, off1=0)\n",
        "    text_map = np.asarray(text_map).astype(np.uint8)\n",
        "\n",
        "    bUpdate = 1\n",
        "    for i in range(num):\n",
        "        attn = attn_maps[i].cpu().view(1, -1, att_sze, att_sze)\n",
        "        #\n",
        "        attn = attn.view(-1, 1, att_sze, att_sze)\n",
        "        attn = attn.repeat(1, 3, 1, 1).data.numpy()\n",
        "        # n x c x h x w --> n x h x w x c\n",
        "        attn = np.transpose(attn, (0, 2, 3, 1))\n",
        "        num_attn = cap_lens[i]\n",
        "        thresh = 2./float(num_attn)\n",
        "        #\n",
        "        img = real_imgs[i]\n",
        "        row = []\n",
        "        row_merge = []\n",
        "        row_txt = []\n",
        "        row_beforeNorm = []\n",
        "        conf_score = []\n",
        "        for j in range(num_attn):\n",
        "            one_map = attn[j]\n",
        "            mask0 = one_map > (2. * thresh)\n",
        "            conf_score.append(np.sum(one_map * mask0))\n",
        "            mask = one_map > thresh\n",
        "            one_map = one_map * mask\n",
        "            if (vis_size // att_sze) > 1:\n",
        "                one_map = \\\n",
        "                    skimage.transform.pyramid_expand(one_map, sigma=20,\n",
        "                                                     upscale=vis_size // att_sze,\n",
        "                                                     multichannel=True)\n",
        "            minV = one_map.min()\n",
        "            maxV = one_map.max()\n",
        "            one_map = (one_map - minV) / (maxV - minV)\n",
        "            row_beforeNorm.append(one_map)\n",
        "        sorted_indices = np.argsort(conf_score)[::-1]\n",
        "\n",
        "        for j in range(num_attn):\n",
        "            one_map = row_beforeNorm[j]\n",
        "            one_map *= 255\n",
        "            #\n",
        "            PIL_im = Image.fromarray(np.uint8(img))\n",
        "            PIL_att = Image.fromarray(np.uint8(one_map))\n",
        "            merged = \\\n",
        "                Image.new('RGBA', (vis_size, vis_size), (0, 0, 0, 0))\n",
        "            mask = Image.new('L', (vis_size, vis_size), (180))  # (210)\n",
        "            merged.paste(PIL_im, (0, 0))\n",
        "            merged.paste(PIL_att, (0, 0), mask)\n",
        "            merged = np.array(merged)[:, :, :3]\n",
        "\n",
        "            row.append(np.concatenate([one_map, middle_pad], 1))\n",
        "            #\n",
        "            row_merge.append(np.concatenate([merged, middle_pad], 1))\n",
        "            #\n",
        "            txt = text_map[i * FONT_MAX:(i + 1) * FONT_MAX,\n",
        "                           j * (vis_size + 2):(j + 1) * (vis_size + 2), :]\n",
        "            row_txt.append(txt)\n",
        "        # reorder\n",
        "        row_new = []\n",
        "        row_merge_new = []\n",
        "        txt_new = []\n",
        "        for j in range(num_attn):\n",
        "            idx = sorted_indices[j]\n",
        "            row_new.append(row[idx])\n",
        "            row_merge_new.append(row_merge[idx])\n",
        "            txt_new.append(row_txt[idx])\n",
        "        row = np.concatenate(row_new[:topK], 1)\n",
        "        row_merge = np.concatenate(row_merge_new[:topK], 1)\n",
        "        txt = np.concatenate(txt_new[:topK], 1)\n",
        "        if txt.shape[1] != row.shape[1]:\n",
        "            print('Warnings: txt', txt.shape, 'row', row.shape,\n",
        "                  'row_merge_new', row_merge_new.shape)\n",
        "            bUpdate = 0\n",
        "            break\n",
        "        row = np.concatenate([txt, row_merge], 0)\n",
        "        img_set.append(row)\n",
        "    if bUpdate:\n",
        "        img_set = np.concatenate(img_set, 0)\n",
        "        img_set = img_set.astype(np.uint8)\n",
        "        return img_set, sentences\n",
        "    else:\n",
        "        return None\n",
        " \n",
        "def load_params(model, new_param):\n",
        "    for p, new_p in zip(model.parameters(), new_param):\n",
        "        p.data.copy_(new_p)\n",
        " \n",
        " \n",
        "def copy_G_params(model):\n",
        "    flatten = deepcopy(list(p.data for p in model.parameters()))\n",
        "    return flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGLFvdwFYSNE"
      },
      "source": [
        "PRETRAIN DAMSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dch2BieT1lx8"
      },
      "source": [
        "UPDATE_INTERVAL = 200\n",
        "def train(dataloader, cnn_model, rnn_model, batch_size,\n",
        "          labels, optimizer, epoch, ixtoword, image_dir):\n",
        "    cnn_model.train()\n",
        "    rnn_model.train()\n",
        "    s_total_loss0 = 0\n",
        "    s_total_loss1 = 0\n",
        "    w_total_loss0 = 0\n",
        "    w_total_loss1 = 0\n",
        "    count = (epoch + 1) * len(dataloader)\n",
        "    start_time = time.time()\n",
        "    for step, data in enumerate(dataloader, 0):\n",
        "        # print('step', step)\n",
        "        rnn_model.zero_grad()\n",
        "        cnn_model.zero_grad()\n",
        "\n",
        "        imgs, captions, cap_lens, \\\n",
        "            class_ids, keys = prepare_data(data)\n",
        "\n",
        "\n",
        "        # words_features: batch_size x nef x 17 x 17\n",
        "        # sent_code: batch_size x nef\n",
        "        words_features, sent_code = cnn_model(imgs[-1])\n",
        "        # --> batch_size x nef x 17*17\n",
        "        nef, att_sze = words_features.size(1), words_features.size(2)\n",
        "        # words_features = words_features.view(batch_size, nef, -1)\n",
        "\n",
        "        hidden = rnn_model.init_hidden(batch_size)\n",
        "        # words_emb: batch_size x nef x seq_len\n",
        "        # sent_emb: batch_size x nef\n",
        "        words_emb, sent_emb = rnn_model(captions, cap_lens, hidden)\n",
        "\n",
        "        w_loss0, w_loss1, attn_maps = words_loss(words_features, words_emb, labels,\n",
        "                                                 cap_lens, class_ids, batch_size)\n",
        "        w_total_loss0 += w_loss0.data\n",
        "        w_total_loss1 += w_loss1.data\n",
        "        loss = w_loss0 + w_loss1\n",
        "\n",
        "        s_loss0, s_loss1 = \\\n",
        "            sent_loss(sent_code, sent_emb, labels, class_ids, batch_size)\n",
        "        loss += s_loss0 + s_loss1\n",
        "        s_total_loss0 += s_loss0.data\n",
        "        s_total_loss1 += s_loss1.data\n",
        "        #\n",
        "        loss.backward()\n",
        "        #\n",
        "        # `clip_grad_norm` helps prevent\n",
        "        # the exploding gradient problem in RNNs / LSTMs.\n",
        "        RNN_GRAD_CLIP=0.25\n",
        "        torch.nn.utils.clip_grad_norm(rnn_model.parameters(),\n",
        "                                      RNN_GRAD_CLIP)\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % UPDATE_INTERVAL == 0:\n",
        "            count = epoch * len(dataloader) + step\n",
        "\n",
        "            s_cur_loss0 = s_total_loss0 / UPDATE_INTERVAL\n",
        "            s_cur_loss1 = s_total_loss1 / UPDATE_INTERVAL\n",
        "\n",
        "            w_cur_loss0 = w_total_loss0 / UPDATE_INTERVAL\n",
        "            w_cur_loss1 = w_total_loss1 / UPDATE_INTERVAL\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '\n",
        "                  's_loss {:5.2f} {:5.2f} | '\n",
        "                  'w_loss {:5.2f} {:5.2f}'\n",
        "                  .format(epoch, step, len(dataloader),\n",
        "                          elapsed * 1000. / UPDATE_INTERVAL,\n",
        "                          s_cur_loss0, s_cur_loss1,\n",
        "                          w_cur_loss0, w_cur_loss1))\n",
        "            s_total_loss0 = 0\n",
        "            s_total_loss1 = 0\n",
        "            w_total_loss0 = 0\n",
        "            w_total_loss1 = 0\n",
        "            start_time = time.time()\n",
        "            # attention Maps\n",
        "            img_set, _ = \\\n",
        "                build_super_images(imgs[-1].cpu(), captions,\n",
        "                                   ixtoword, attn_maps, att_sze)\n",
        "            if img_set is not None:\n",
        "                im = Image.fromarray(img_set)\n",
        "                fullpath = '%s/attention_maps%d.png' % (image_dir, step)\n",
        "                im.save(fullpath)\n",
        "    return count\n",
        "\n",
        "\n",
        "def evaluate(dataloader, cnn_model, rnn_model, batch_size):\n",
        "    cnn_model.eval()\n",
        "    rnn_model.eval()\n",
        "    s_total_loss = 0\n",
        "    w_total_loss = 0\n",
        "    for step, data in enumerate(dataloader, 0):\n",
        "        real_imgs, captions, cap_lens, \\\n",
        "                class_ids, keys = prepare_data(data)\n",
        "\n",
        "        words_features, sent_code = cnn_model(real_imgs[-1])\n",
        "        # nef = words_features.size(1)\n",
        "        # words_features = words_features.view(batch_size, nef, -1)\n",
        "\n",
        "        hidden = rnn_model.init_hidden(batch_size)\n",
        "        words_emb, sent_emb = rnn_model(captions, cap_lens, hidden)\n",
        "\n",
        "        w_loss0, w_loss1, attn = words_loss(words_features, words_emb, labels,\n",
        "                                            cap_lens, class_ids, batch_size)\n",
        "        w_total_loss += (w_loss0 + w_loss1).data\n",
        "\n",
        "        s_loss0, s_loss1 = \\\n",
        "            sent_loss(sent_code, sent_emb, labels, class_ids, batch_size)\n",
        "        s_total_loss += (s_loss0 + s_loss1).data\n",
        "\n",
        "        if step == 50:\n",
        "            break\n",
        "\n",
        "    s_cur_loss = s_total_loss[0] / step\n",
        "    w_cur_loss = w_total_loss[0] / step\n",
        "\n",
        "    return s_cur_loss, w_cur_loss\n",
        "\n",
        "\n",
        "def build_models():\n",
        "    text_encoder = RNN_ENCODER(dataset.n_words, nhidden=EMBEDDING_DIM)\n",
        "    image_encoder = CNN_ENCODER(EMBEDDING_DIM)\n",
        "    labels = Variable(torch.LongTensor(range(batch_size)))\n",
        "    start_epoch = 0\n",
        "    text_encoder = text_encoder.cuda()\n",
        "    image_encoder = image_encoder.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    return text_encoder, image_encoder, labels, start_epoch\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    manualSeed = random.randint(1, 10000)\n",
        "    random.seed(manualSeed)\n",
        "    np.random.seed(manualSeed)\n",
        "    torch.manual_seed(manualSeed)\n",
        "    torch.cuda.manual_seed_all(manualSeed)\n",
        "\n",
        "    ##########################################################################\n",
        "    output_dir = '/content/gdrive/My Drive/Saumya/output/'\n",
        "\n",
        "    model_dir = os.path.join(output_dir, 'Model')\n",
        "    image_dir = os.path.join(output_dir, 'Image')\n",
        "    torch.cuda.set_device(GPU_ID)\n",
        "    cudnn.benchmark = True\n",
        "    # Get data loader ##################################################\n",
        "    imsize = BASE_SIZE * (2 ** (BRANCH_NUM-1))\n",
        "    batch_size = BATCH_SIZE\n",
        "    image_transform = transforms.Compose([\n",
        "        transforms.Scale(int(imsize * 76 / 64)),\n",
        "        transforms.RandomCrop(imsize),\n",
        "        transforms.RandomHorizontalFlip()])\n",
        "    dataset = TextDataset(DATA_DIR, 'train',\n",
        "                          base_size=BASE_SIZE,\n",
        "                          transform=image_transform)\n",
        "\n",
        "    print(dataset.n_words, dataset.embeddings_num)\n",
        "    assert dataset\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, drop_last=True,\n",
        "        shuffle=False, num_workers=int(WORKERS))\n",
        "\n",
        "    # # validation data #\n",
        "    dataset_val = TextDataset(DATA_DIR, 'test',\n",
        "                              base_size=BASE_SIZE,\n",
        "                              transform=image_transform)\n",
        "    dataloader_val = torch.utils.data.DataLoader(\n",
        "        dataset_val, batch_size=batch_size, drop_last=True,\n",
        "        shuffle=True, num_workers=int(WORKERS))\n",
        "\n",
        "    # Train ##############################################################\n",
        "    text_encoder, image_encoder, labels, start_epoch = build_models()\n",
        "    para = list(text_encoder.parameters())\n",
        "    for v in image_encoder.parameters():\n",
        "        if v.requires_grad:\n",
        "            para.append(v)\n",
        "    # optimizer = optim.Adam(para, lr=ENCODER_LR, betas=(0.5, 0.999))\n",
        "    # At any point you can hit Ctrl + C to break out of training early.\n",
        "    lr = ENCODER_LR\n",
        "    for epoch in range(start_epoch,MAX_EPOCH):\n",
        "        optimizer = optim.Adam(para, lr=lr, betas=(0.5, 0.999))\n",
        "        epoch_start_time = time.time()\n",
        "        count = train(dataloader, image_encoder, text_encoder,\n",
        "                      batch_size, labels, optimizer, epoch,\n",
        "                      dataset.ixtoword, image_dir)\n",
        "        print('-' * 89)\n",
        "        if len(dataloader_val) > 0:\n",
        "            s_loss, w_loss = evaluate(dataloader_val, image_encoder,\n",
        "                                      text_encoder, batch_size)\n",
        "            print('| end epoch {:3d} | valid loss '\n",
        "                  '{:5.2f} {:5.2f} | lr {:.5f}|'\n",
        "                  .format(epoch, s_loss, w_loss, lr))\n",
        "        #print('-' * 89)\n",
        "        if lr > ENCODER_LR/10.:\n",
        "            lr *= 0.98\n",
        "\n",
        "        if (epoch % SNAPSHOT_INTERVAL == 0 or\n",
        "            epoch == MAX_EPOCH):\n",
        "            torch.save(image_encoder.state_dict(),\n",
        "                        '%s/image_encoder%d.pth' % (model_dir, epoch))\n",
        "            torch.save(text_encoder.state_dict(),\n",
        "                        '%s/text_encoder%d.pth' % (model_dir, epoch))\n",
        "            print('Save G/Ds models.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buDrsg1EeIsh"
      },
      "source": [
        "Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8Jw-xldZtec"
      },
      "source": [
        "NET_E='/content/gdrive/My Drive/Saumya/output/text_encoder200.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-WB0J1MVb8s"
      },
      "source": [
        "real_imgs=[]\n",
        "fake_images=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EPsF64QMoXp"
      },
      "source": [
        "from __future__ import print_function\n",
        "from six.moves import range\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHDb45rcNCXM"
      },
      "source": [
        "class condGANTrainer(object):\n",
        "    def __init__(self, output_dir, data_loader, n_words, ixtoword):\n",
        "        self.model_dir = os.path.join(output_dir, 'Model')\n",
        "        self.image_dir = os.path.join(output_dir, 'Image')\n",
        "        # mkdir_p(self.model_dir)\n",
        "        # mkdir_p(self.image_dir)\n",
        " \n",
        "        torch.cuda.set_device(GPU_ID)\n",
        "        cudnn.benchmark = True\n",
        "        self.dataset=dataset\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.max_epoch = MAX_EPOCH\n",
        "        self.snapshot_interval = SNAPSHOT_INTERVAL\n",
        " \n",
        "        self.n_words = n_words\n",
        "        self.ixtoword = ixtoword\n",
        "        self.data_loader = data_loader\n",
        "        self.num_batches = len(self.data_loader)\n",
        " \n",
        "    def build_models(self):\n",
        "        # ###################encoders######################################## #\n",
        "        image_encoder = CNN_ENCODER(EMBEDDING_DIM)\n",
        "        img_encoder_path =NET_E.replace('text_encoder', 'image_encoder')\n",
        "        state_dict = \\\n",
        "            torch.load(img_encoder_path, map_location=lambda storage, loc: storage)\n",
        "        image_encoder.load_state_dict(state_dict)\n",
        "        for p in image_encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "        print('Load image encoder from:', img_encoder_path)\n",
        "        image_encoder.eval()\n",
        " \n",
        "        text_encoder = RNN_ENCODER(self.n_words, nhidden=EMBEDDING_DIM)\n",
        "        state_dict = torch.load(NET_E,\n",
        "                       map_location=lambda storage, loc: storage)\n",
        "        text_encoder.load_state_dict(state_dict)\n",
        "        for p in text_encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "        print('Load text encoder from:',NET_E)\n",
        "        text_encoder.eval()\n",
        " \n",
        "        # #######################generator and discriminators############## #\n",
        "        netsD = []\n",
        "        if  B_DCGAN:\n",
        "            if BRANCH_NUM ==1:\n",
        "                from model import D_NET64 as D_NET\n",
        "            elif BRANCH_NUM == 2:\n",
        "                from model import D_NET128 as D_NET\n",
        "            else:  # BRANCH_NUM == 3:\n",
        "                from model import D_NET256 as D_NET\n",
        "            # TODO: elif BRANCH_NUM > 3:\n",
        "            netG = G_DCGAN()\n",
        "            netsD = [D_NET(b_jcu=False)]\n",
        "        else:\n",
        "            netG = G_NET()\n",
        "            if BRANCH_NUM > 0:\n",
        "                netsD.append(D_NET64())\n",
        "            if BRANCH_NUM > 1:\n",
        "                netsD.append(D_NET128())\n",
        "            if BRANCH_NUM > 2:\n",
        "                netsD.append(D_NET256())\n",
        "            # TODO: if BRANCH_NUM > 3:\n",
        "        netG.apply(weights_init)\n",
        "        # print(netG)\n",
        "        for i in range(len(netsD)):\n",
        "            netsD[i].apply(weights_init)\n",
        "            # print(netsD[i])\n",
        "        print('# of netsD', len(netsD))\n",
        "        #\n",
        "        epoch = 0\n",
        "        if NET_G != '':\n",
        "            state_dict = \\\n",
        "                torch.load(NET_G, map_location=lambda storage, loc: storage)\n",
        "            netG.load_state_dict(state_dict,strict=False)\n",
        "            print('Load G from: ',NET_G)\n",
        "            istart = NET_G.rfind('_') + 1\n",
        "            iend = NET_G.rfind('.')\n",
        "            epoch = NET_G[istart:iend]\n",
        "            epoch = int(epoch) + 1\n",
        "            B_NET_D=True\n",
        "            if B_NET_D:\n",
        "                Gname = NET_G\n",
        "                for i in range(len(netsD)):\n",
        "                    s_tmp = Gname[:Gname.rfind('/')]\n",
        "                    Dname = '%s/netD%d.pth' % (s_tmp, i)\n",
        "                    print('Load D from: ', Dname)\n",
        "                    state_dict = \\\n",
        "                        torch.load(Dname, map_location=lambda storage, loc: storage)\n",
        "                    netsD[i].load_state_dict(state_dict)\n",
        "        # ########################################################### #\n",
        "        text_encoder = text_encoder.cuda()\n",
        "        image_encoder = image_encoder.cuda()\n",
        "        netG.cuda()\n",
        "        for i in range(len(netsD)):\n",
        "          netsD[i].cuda()\n",
        "        return [text_encoder, image_encoder, netG, netsD, epoch]\n",
        " \n",
        "    def define_optimizers(self, netG, netsD):\n",
        "        optimizersD = []\n",
        "        num_Ds = len(netsD)\n",
        "        for i in range(num_Ds):\n",
        "            opt = optim.Adam(netsD[i].parameters(),\n",
        "                             lr=DISCRIMINATOR_LR,\n",
        "                             betas=(0.5, 0.999))\n",
        "            optimizersD.append(opt)\n",
        " \n",
        "        optimizerG = optim.Adam(netG.parameters(),\n",
        "                                lr=GENERATOR_LR,\n",
        "                                betas=(0.5, 0.999))\n",
        " \n",
        "        return optimizerG, optimizersD\n",
        " \n",
        "    def prepare_labels(self):\n",
        "        batch_size = self.batch_size\n",
        "        real_labels = Variable(torch.FloatTensor(batch_size).fill_(1))\n",
        "        fake_labels = Variable(torch.FloatTensor(batch_size).fill_(0))\n",
        "        match_labels = Variable(torch.LongTensor(range(batch_size)))\n",
        "        real_labels = real_labels.cuda()\n",
        "        fake_labels = fake_labels.cuda()\n",
        "        match_labels = match_labels.cuda()\n",
        " \n",
        "        return real_labels, fake_labels, match_labels\n",
        " \n",
        "    def save_model(self, netG, avg_param_G, netsD, epoch):\n",
        "        backup_para = copy_G_params(netG)\n",
        "        load_params(netG, avg_param_G)\n",
        "        torch.save(netG.state_dict(),\n",
        "            '%s/netG_epoch_%d.pth' % ('/content/gdrive/My Drive/Saumya/output/Model', epoch))\n",
        "        load_params(netG, backup_para)\n",
        "        #\n",
        "        for i in range(len(netsD)):\n",
        "            netD = netsD[i]\n",
        "            torch.save(netD.state_dict(),\n",
        "                '%s/netD%d.pth' % ('/content/gdrive/My Drive/Saumya/output/Model', i))\n",
        "        print('Save G/Ds models.')\n",
        " \n",
        "    def set_requires_grad_value(self, models_list, brequires):\n",
        "        for i in range(len(models_list)):\n",
        "            for p in models_list[i].parameters():\n",
        "                p.requires_grad = brequires\n",
        " \n",
        "    def save_img_results(self, netG, noise, sent_emb, words_embs, mask,\n",
        "                        image_encoder, captions, cap_lens,\n",
        "                        gen_iterations, name='current'):\n",
        "      # Save images\n",
        "      fake_imgs, attention_maps, _, _ = netG(noise, sent_emb, words_embs, mask)\n",
        "      for i in range(len(attention_maps)):\n",
        "          if len(fake_imgs) > 1:\n",
        "              img = fake_imgs[i + 1].detach().cpu()\n",
        "              lr_img = fake_imgs[i].detach().cpu()\n",
        "          else:\n",
        "              img = fake_imgs[0].detach().cpu()\n",
        "              lr_img = None\n",
        "          attn_maps = attention_maps[i]\n",
        "          att_sze = attn_maps.size(2)\n",
        "          img_set, _ = \\\n",
        "              build_super_images(img, captions, self.ixtoword,\n",
        "                                  attn_maps, att_sze, lr_imgs=lr_img)\n",
        "          if img_set is not None:\n",
        "              im = Image.fromarray(img_set)\n",
        "              fullpath = '%s/G_%s_%d_%d.png'\\\n",
        "                  % (self.image_dir, name, gen_iterations, i)\n",
        "              im.save(fullpath)\n",
        " \n",
        "      # for i in range(len(netsD)):\n",
        "      i = -1\n",
        "      img = fake_imgs[i].detach()\n",
        "      region_features, _ = image_encoder(img)\n",
        "      att_sze = region_features.size(2)\n",
        "      _, _, att_maps = words_loss(region_features.detach(),\n",
        "                                  words_embs.detach(),\n",
        "                                  None, cap_lens,\n",
        "                                  None, self.batch_size)\n",
        "      img_set, _ = \\\n",
        "          build_super_images(fake_imgs[i].detach().cpu(),\n",
        "                              captions, self.ixtoword, att_maps, att_sze)\n",
        "      if img_set is not None:\n",
        "          im = Image.fromarray(img_set)\n",
        "          fullpath = '%s/D_%s_%d.png'\\\n",
        "              % (self.image_dir, name, gen_iterations)\n",
        "          im.save(fullpath)\n",
        "\n",
        "    def train(self):\n",
        "        text_encoder, image_encoder, netG, netsD, start_epoch = self.build_models()\n",
        "        avg_param_G = copy_G_params(netG)\n",
        "        optimizerG, optimizersD = self.define_optimizers(netG, netsD)\n",
        "        real_labels, fake_labels, match_labels = self.prepare_labels()\n",
        " \n",
        "        batch_size = self.batch_size\n",
        "        nz = Z_DIM\n",
        "        noise = Variable(torch.FloatTensor(batch_size, nz))\n",
        "        fixed_noise = Variable(torch.FloatTensor(batch_size, nz).normal_(0, 1))\n",
        "        noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
        " \n",
        "        gen_iterations = 0\n",
        "        # gen_iterations = start_epoch * self.num_batches\n",
        "        for epoch in range(start_epoch, self.max_epoch):\n",
        "            start_t = time.time()\n",
        " \n",
        "            data_iter = iter(self.data_loader)\n",
        "            step = 0\n",
        "            errD_total=0\n",
        "            errG_total=0\n",
        "            while step < self.num_batches:\n",
        "                # reset requires_grad to be trainable for all Ds\n",
        "                # self.set_requires_grad_value(netsD, True)\n",
        " \n",
        "                ######################################################\n",
        "                # (1) Prepare training data and Compute text embeddings\n",
        "                ######################################################\n",
        "                data = data_iter.next()\n",
        "                imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
        " \n",
        "                hidden = text_encoder.init_hidden(batch_size)\n",
        "                # words_embs: batch_size x nef x seq_len\n",
        "                # sent_emb: batch_size x nef\n",
        "                words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
        "                words_embs, sent_emb = words_embs.detach(), sent_emb.detach()\n",
        "                mask = (captions == 0)\n",
        "                num_words = words_embs.size(2)\n",
        "                if mask.size(1) > num_words:\n",
        "                    mask = mask[:, :num_words]\n",
        " \n",
        "                #######################################################\n",
        "                # (2) Generate fake images\n",
        "                ######################################################\n",
        "                noise.data.normal_(0, 1)\n",
        "                fake_imgs, _, mu, logvar = netG(noise, sent_emb, words_embs, mask)\n",
        " \n",
        "                #######################################################\n",
        "                # (3) Update D network\n",
        "                ######################################################\n",
        "                errD_total = 0\n",
        "                D_logs = ''\n",
        "                \n",
        "                for i in range(len(netsD)):\n",
        "                    netsD[i].zero_grad()\n",
        "                    errD=discriminator_loss(netsD[i], imgs[i], fake_imgs[i],\n",
        "                                              sent_emb, real_labels, fake_labels)\n",
        "                    # backward and update parameters\n",
        "                    errD.backward()\n",
        "                    optimizersD[i].step()\n",
        "                    errD_total += errD\n",
        "                    D_logs += 'errD%d: %.2f ' % (i, errD)\n",
        " \n",
        "                #######################################################\n",
        "                # (4) Update G network: maximize log(D(G(z)))\n",
        "                ######################################################\n",
        "                # compute total loss for training G\n",
        "                step += 1\n",
        "                gen_iterations += 1\n",
        " \n",
        "                # do not need to compute gradient for Ds\n",
        "                # self.set_requires_grad_value(netsD, False)\n",
        "                netG.zero_grad()\n",
        "                errG_total, G_logs = \\\n",
        "                    generator_loss(netsD, image_encoder, fake_imgs, real_labels,\n",
        "                                   words_embs, sent_emb, match_labels, cap_lens, class_ids)\n",
        "                kl_loss =KL_loss(mu, logvar)\n",
        "                \n",
        "                errG_total += kl_loss\n",
        "                G_logs += 'kl_loss: %.2f ' % kl_loss\n",
        "                # backward and update parameters\n",
        "                errG_total.requires_grad=True\n",
        "                errG_total.backward()\n",
        "                optimizerG.step()\n",
        "                for p, avg_p in zip(netG.parameters(), avg_param_G):\n",
        "                    avg_p.mul_(0.999).add_(0.001, p.data)\n",
        " \n",
        "                if gen_iterations % 100 == 0:\n",
        "                    print(D_logs + '\\n' + G_logs)\n",
        "                # save images\n",
        "                if gen_iterations % 1000 == 0:\n",
        "                    backup_para = copy_G_params(netG)\n",
        "                    load_params(netG, avg_param_G)\n",
        "                    self.save_img_results(netG, fixed_noise, sent_emb,\n",
        "                                          words_embs, mask, image_encoder,\n",
        "                                          captions, cap_lens, epoch, name='average')\n",
        "                    load_params(netG, backup_para)\n",
        "                    #\n",
        "                    # self.save_img_results(netG, fixed_noise, sent_emb,\n",
        "                    #                       words_embs, mask, image_encoder,\n",
        "                    #                       captions, cap_lens,\n",
        "                    #                       epoch, name='current')\n",
        "            end_t = time.time()\n",
        " \n",
        "            print('''[%d/%d][%d]\n",
        "                  Loss_D: %.2f Loss_G: %.2f Time: %.2fs'''\n",
        "                  % (epoch, self.max_epoch, self.num_batches,\n",
        "                     errD_total, errG_total,\n",
        "                     end_t - start_t))\n",
        " \n",
        "            if epoch % SNAPSHOT_INTERVAL == 0:  # and epoch != 0:\n",
        "                self.save_model(netG, avg_param_G, netsD, epoch)\n",
        " \n",
        "        self.save_model(netG, avg_param_G, netsD, self.max_epoch)\n",
        " \n",
        "    def save_singleimages(self, images, filenames, save_dir,\n",
        "                          split_dir, sentenceID=0):\n",
        "        for i in range(images.size(0)):\n",
        "            s_tmp = '%s/single_samples/%s/%s' %\\\n",
        "                (save_dir, split_dir, filenames[i])\n",
        "            folder = s_tmp[:s_tmp.rfind('/')]\n",
        "            if not os.path.isdir(folder):\n",
        "                print('Make a new folder: ', folder)\n",
        "                mkdir_p(folder)\n",
        " \n",
        "            fullpath = '%s_%d.jpg' % (s_tmp, sentenceID)\n",
        "            # range from [-1, 1] to [0, 1]\n",
        "            # img = (images[i] + 1.0) / 2\n",
        "            img = images[i].add(1).div(2).mul(255).clamp(0, 255).byte()\n",
        "            # range from [0, 1] to [0, 255]\n",
        "            ndarr = img.permute(1, 2, 0).data.cpu().numpy()\n",
        "            im = Image.fromarray(ndarr)\n",
        "            im.save(fullpath)\n",
        " \n",
        "    def sampling(self, split_dir):\n",
        "        if NET_G == '':\n",
        "            print('Error: the path for morels is not found!')\n",
        "        else:\n",
        "            if split_dir == 'test':\n",
        "                split_dir = 'valid'\n",
        "            # Build and load the generator\n",
        "            if B_DCGAN:\n",
        "                netG = G_DCGAN()\n",
        "            else:\n",
        "                netG = G_NET()\n",
        "            netG.apply(weights_init)\n",
        "            netG.cuda()\n",
        "            netG.eval()\n",
        "            text_encoder = RNN_ENCODER(self.n_words, nhidden=EMBEDDING_DIM)\n",
        "            state_dict = \\\n",
        "                torch.load(NET_E, map_location=lambda storage, loc: storage)\n",
        "            text_encoder.load_state_dict(state_dict)\n",
        "            print('Load text encoder from:', NET_E)\n",
        "            text_encoder = text_encoder.cuda()\n",
        "            text_encoder.eval()\n",
        "            \n",
        "            image_encoder = CNN_ENCODER(EMBEDDING_DIM)\n",
        "            img_encoder_path = NET_E.replace('text_encoder', 'image_encoder')\n",
        "            state_dict = torch.load(img_encoder_path, map_location=lambda storage, loc: storage)\n",
        "            image_encoder.load_state_dict(state_dict)\n",
        "            print('Load image encoder from:', img_encoder_path)\n",
        "            image_encoder = image_encoder.cuda()\n",
        "            image_encoder.eval()\n",
        "            batch_size = self.batch_size\n",
        "            nz = Z_DIM\n",
        "            noise = Variable(torch.FloatTensor(batch_size, nz), volatile=True)\n",
        "            noise = noise.cuda()\n",
        " \n",
        "            model_dir = NET_G\n",
        "            state_dict = \\\n",
        "                torch.load(model_dir, map_location=lambda storage, loc: storage)\n",
        "            # state_dict = torch.load(NET_G)\n",
        "            netG.load_state_dict(state_dict)\n",
        "            print('Load G from: ', model_dir)\n",
        "            save_dir = '/content/gdrive/My Drive/Saumya/output/Image/AttGAN'\n",
        "            # print('Generating Images!!!')\n",
        "            cnt = 0\n",
        "            R_count = 0\n",
        "            R = np.zeros(30000)\n",
        "            cont = True\n",
        "            cnt = 0\n",
        "            R_count = 0\n",
        "            R = np.zeros(30000)\n",
        "            cont = True\n",
        "            for ii in range(11):  # (CAPTIONS_PER_IMAGE):\n",
        "                if (cont == False):\n",
        "                    break\n",
        "                for step, data in enumerate(self.data_loader, 0):\n",
        "                    cnt += batch_size\n",
        "                    if (cont == False):\n",
        "                        break\n",
        "                    if step % 100 == 0:\n",
        "                       print('cnt: ', cnt)\n",
        "                    # if step > 50:\n",
        "                    #     break\n",
        " \n",
        "                    imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
        "                    # print('Data Prepared!!!')\n",
        "                    hidden = text_encoder.init_hidden(batch_size)\n",
        "                    # words_embs: batch_size x nef x seq_len\n",
        "                    # sent_emb: batch_size x nef\n",
        "                    words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
        "                    words_embs, sent_emb = words_embs.detach(), sent_emb.detach()\n",
        "                    mask = (captions == 0)\n",
        "                    num_words = words_embs.size(2)\n",
        "                    if mask.size(1) > num_words:\n",
        "                        mask = mask[:, :num_words]\n",
        " \n",
        "                    #######################################################\n",
        "                    # (2) Generate fake images\n",
        "                    ######################################################\n",
        "                    noise.data.normal_(0, 1)\n",
        "                    fake_imgs, _, _, _ = netG(noise, sent_emb, words_embs, mask)\n",
        "                    for j in range(batch_size):\n",
        "                        s_tmp = '%s/single/%s' % (save_dir, keys[j])\n",
        "                        folder = s_tmp[:s_tmp.rfind('/')]\n",
        "                        if not os.path.isdir(folder):\n",
        "                            #print('Make a new folder: ', folder)\n",
        "                            mkdir_p(folder)\n",
        "                        k = -1\n",
        "                        # for k in range(len(fake_imgs)):\n",
        "                        im = fake_imgs[k][j].data.cpu().numpy()\n",
        "                        # [-1, 1] --> [0, 255]\n",
        "                        im = (im + 1.0) * 127.5\n",
        "                        im = im.astype(np.uint8)\n",
        "                        im = np.transpose(im, (1, 2, 0))\n",
        "                        im = Image.fromarray(im)\n",
        "                        fullpath = '%s_s%d_%d.png' % (s_tmp, k, ii)\n",
        "                        im.save(fullpath)\n",
        " \n",
        "                    _, cnn_code = image_encoder(fake_imgs[-1])\n",
        "                    _, cnn_code_real = image_encoder(imgs[-1])\n",
        "                    real_imgs.append(cnn_code_real)\n",
        "                    fake_images.append(cnn_code)\n",
        " \n",
        "                    for i in range(batch_size):\n",
        "                        mis_captions, mis_captions_len = self.dataset.get_mis_caption(class_ids[i])\n",
        "                        hidden = text_encoder.init_hidden(99)\n",
        "                        _, sent_emb_t = text_encoder(mis_captions, mis_captions_len, hidden)\n",
        "                        rnn_code = torch.cat((sent_emb[i, :].unsqueeze(0), sent_emb_t), 0)\n",
        "                        scores = torch.mm(cnn_code[i].unsqueeze(0), rnn_code.transpose(0, 1))  # 1* 100\n",
        "                        cnn_code_norm = torch.norm(cnn_code[i].unsqueeze(0), 2, dim=1, keepdim=True)\n",
        "                        rnn_code_norm = torch.norm(rnn_code, 2, dim=1, keepdim=True)\n",
        "                        norm = torch.mm(cnn_code_norm, rnn_code_norm.transpose(0, 1))\n",
        "                        scores0 = scores / norm.clamp(min=1e-8)\n",
        "                        if torch.argmax(scores0) == 0 and R_count<=30000:\n",
        "                            R[R_count] = 1\n",
        "                        R_count += 1\n",
        " \n",
        "                    if R_count >= 30000:\n",
        "                        sum = np.zeros(10)\n",
        "                        np.random.shuffle(R)\n",
        "                        for i in range(10):\n",
        "                            sum[i] = np.average(R[i * 3000:(i + 1) * 3000 - 1])\n",
        "                        R_mean = np.average(sum)\n",
        "                        R_std = np.std(sum)\n",
        "                        print(\"R mean:{:.4f} std:{:.4f}\".format(R_mean, R_std))\n",
        "                        cont = False\n",
        "            \n",
        " \n",
        " \n",
        "    def gen_example(self, data_dic):\n",
        "   \n",
        "        if NET_G == '':\n",
        "            print('Error: the path for morels is not found!')\n",
        "        else:\n",
        "            # Build and load the generator\n",
        "            text_encoder = \\\n",
        "                RNN_ENCODER(self.n_words, nhidden=EMBEDDING_DIM)\n",
        "            state_dict = \\\n",
        "                torch.load(NET_E, map_location=lambda storage, loc: storage)\n",
        "            text_encoder.load_state_dict(state_dict)\n",
        "            print('Load text encoder from:',NET_E)\n",
        "            text_encoder = text_encoder.cuda()\n",
        "            text_encoder.eval()\n",
        "            # the path to save generated images\n",
        "            if B_DCGAN:\n",
        "                netG = G_DCGAN()\n",
        "            else:\n",
        "                netG = G_NET()\n",
        "            s_tmp = NET_G[:NET_G.rfind('.pth')]\n",
        "            model_dir = NET_G\n",
        "            state_dict = \\\n",
        "                torch.load(model_dir, map_location=lambda storage, loc: storage)\n",
        "            netG.load_state_dict(state_dict)\n",
        "            print('Load G from: ', model_dir)\n",
        "            netG.cuda()\n",
        "            netG.eval()\n",
        "            for key in data_dic:\n",
        "                save_dir = '/content/gdrive/My Drive/Saumya/output/Image'\n",
        "                #mkdir_p(save_dir)\n",
        "                captions, cap_lens, sorted_indices = data_dic[key]\n",
        " \n",
        "                batch_size = captions.shape[0]\n",
        "                nz = Z_DIM\n",
        "                captions = Variable(torch.from_numpy(captions), volatile=True)\n",
        "                cap_lens = Variable(torch.from_numpy(cap_lens), volatile=True)\n",
        " \n",
        "                captions = captions.cuda()\n",
        "                cap_lens = cap_lens.cuda()\n",
        "                for i in range(1):  # 16\n",
        "                    noise = Variable(torch.FloatTensor(batch_size, nz), volatile=True)\n",
        "                    noise = noise.cuda()\n",
        "                    #######################################################\n",
        "                    # (1) Extract text embeddings\n",
        "                    ######################################################\n",
        "                    hidden = text_encoder.init_hidden(batch_size)\n",
        "                    # words_embs: batch_size x nef x seq_len\n",
        "                    # sent_emb: batch_size x nef\n",
        "                    words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
        "                    mask = (captions == 0)\n",
        "                    #######################################################\n",
        "                    # (2) Generate fake images\n",
        "                    ######################################################\n",
        "                    noise.data.normal_(0, 1)\n",
        "                    fake_imgs, attention_maps, _, _ = netG(noise, sent_emb, words_embs, mask)\n",
        "                    # G attention\n",
        "                    cap_lens_np = cap_lens.cpu().data.numpy()\n",
        "                    for j in range(batch_size):\n",
        "                        save_name = '%s/%d_s_%d' % (save_dir, i, sorted_indices[j])\n",
        "                        for k in range(len(fake_imgs)):\n",
        "                            im = fake_imgs[k][j].data.cpu().numpy()\n",
        "                            im = (im + 1.0) * 127.5\n",
        "                            im = im.astype(np.uint8)\n",
        "                            # print('im', im.shape)\n",
        "                            im = np.transpose(im, (1, 2, 0))\n",
        "                            # print('im', im.shape)\n",
        "                            im = Image.fromarray(im)\n",
        "                            fullpath = '%s_g%d.png' % (save_name, k)\n",
        "                            im.save(fullpath)\n",
        " \n",
        "                        for k in range(len(attention_maps)):\n",
        "                            if len(fake_imgs) > 1:\n",
        "                                im = fake_imgs[k + 1].detach().cpu()\n",
        "                            else:\n",
        "                                im = fake_imgs[0].detach().cpu()\n",
        "                            attn_maps = attention_maps[k]\n",
        "                            att_sze = attn_maps.size(2)\n",
        "                            img_set, sentences = \\\n",
        "                                build_super_images2(im[j].unsqueeze(0),\n",
        "                                                    captions[j].unsqueeze(0),\n",
        "                                                    [cap_lens_np[j]], self.ixtoword,\n",
        "                                                    [attn_maps[j]], att_sze)\n",
        "                            if img_set is not None:\n",
        "                                im = Image.fromarray(img_set)\n",
        "                                fullpath = '%s_a%d.png' % (save_name, k)\n",
        "                                im.save(fullpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHw0BH79eOwX"
      },
      "source": [
        "Main file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDRSkEKBTw14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783,
          "referenced_widgets": [
            "75db773625a54ab3bb793e9e581db847",
            "d13319dcc0b94f8ea2d77b565c0baaf6",
            "9e18dbd273884bdeace678124ae5faa5",
            "8cad500f9fc4432db18ad0d2b3cef620",
            "a7bc320485024750bc77f7f654ffb262",
            "41d101ce5b0b4fcc98ceaff2b06e60f3",
            "bf666864f3b745ee8d1863e53372d503",
            "1224a063bbe746d28c63bd2c2dab4873"
          ]
        },
        "outputId": "c3fb2b54-67bf-4740-d2bc-520bd9c143bc"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import pprint\n",
        "import datetime\n",
        "import dateutil.tz\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "dir_path = ''\n",
        "DATA_DIR='/content/gdrive/My Drive/Saumya/birds/birds'\n",
        "sys.path.append(dir_path)\n",
        "def gen_example(wordtoix, algo):\n",
        "    '''generate images from example sentences'''\n",
        "    from nltk.tokenize import RegexpTokenizer\n",
        "    filepath = '/content/gdrive/My Drive/Saumya/birds/birds/example_filenames.txt'\n",
        "    data_dic = {}\n",
        "    with open(filepath, \"r\") as f:\n",
        "        filenames = f.read().split('\\n')\n",
        "        for name in filenames:\n",
        "            if len(name) == 0:\n",
        "                continue\n",
        "            filepath = '%s/%s.txt' % ('/content/gdrive/My Drive/Saumya/birds/birds', name)\n",
        "            with open(filepath, \"r\") as f:\n",
        "                print('Load from:', name)\n",
        "                sentences = f.read().split('\\n')\n",
        "                # a list of indices for a sentence\n",
        "                captions = []\n",
        "                cap_lens = []\n",
        "                for sent in sentences:\n",
        "                    if len(sent) == 0:\n",
        "                        continue\n",
        "                    sent = sent.replace(\"\\ufffd\\ufffd\", \" \")\n",
        "                    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "                    tokens = tokenizer.tokenize(sent.lower())\n",
        "                    if len(tokens) == 0:\n",
        "                        print('sent', sent)\n",
        "                        continue\n",
        "\n",
        "                    rev = []\n",
        "                    for t in tokens:\n",
        "                        t = t.encode('ascii', 'ignore').decode('ascii')\n",
        "                        if len(t) > 0 and t in wordtoix:\n",
        "                            rev.append(wordtoix[t])\n",
        "                    captions.append(rev)\n",
        "                    cap_lens.append(len(rev))\n",
        "            max_len = np.max(cap_lens)\n",
        "\n",
        "            sorted_indices = np.argsort(cap_lens)[::-1]\n",
        "            cap_lens = np.asarray(cap_lens)\n",
        "            cap_lens = cap_lens[sorted_indices]\n",
        "            cap_array = np.zeros((len(captions), max_len), dtype='int64')\n",
        "            for i in range(len(captions)):\n",
        "                idx = sorted_indices[i]\n",
        "                cap = captions[idx]\n",
        "                c_len = len(cap)\n",
        "                cap_array[i, :c_len] = cap\n",
        "            key = name[(name.rfind('/') + 1):]\n",
        "            data_dic[key] = [cap_array, cap_lens, sorted_indices]\n",
        "    algo.gen_example(data_dic)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    manualSeed = random.randint(1, 10000)\n",
        "    random.seed(manualSeed)\n",
        "    np.random.seed(manualSeed)\n",
        "    torch.manual_seed(manualSeed)\n",
        "    torch.cuda.manual_seed_all(manualSeed)\n",
        "  \n",
        "    output_dir = '/content/gdrive/My Drive/Saumya/output/'\n",
        "\n",
        "    split_dir, bshuffle = 'train', True\n",
        "    if not FLAG:\n",
        "        split_dir = 'test'\n",
        "\n",
        "    # Get data loader\n",
        "    imsize = BASE_SIZE * (2 ** (BRANCH_NUM - 1))\n",
        "    image_transform = transforms.Compose([\n",
        "        transforms.Scale(int(imsize * 76 / 64)),\n",
        "        transforms.RandomCrop(imsize),\n",
        "        transforms.RandomHorizontalFlip()])\n",
        "    dataset = TextDataset(DATA_DIR, split_dir,\n",
        "                          base_size=BASE_SIZE,\n",
        "                          transform= image_transform)\n",
        "    assert dataset\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=BATCH_SIZE,\n",
        "        drop_last=True, shuffle=False, num_workers=int(WORKERS))\n",
        "\n",
        "    # Define models and go to train/evaluate\n",
        "    algo = condGANTrainer(output_dir, dataloader, dataset.n_words, dataset.ixtoword)\n",
        "\n",
        "    start_t = time.time()\n",
        "    if FLAG:\n",
        "      with torch.no_grad():\n",
        "        algo.train()\n",
        "      end_t = time.time()\n",
        "      print('Total time for training:', end_t - start_t)\n",
        "    else:\n",
        "        B_VALIDATION=False\n",
        "        if B_VALIDATION:\n",
        "          with torch.no_grad():\n",
        "            algo.sampling(split_dir)  # generate images for the whole valid dataset\n",
        "        else:\n",
        "            gen_example(dataset.wordtoix, algo)  # generate images for customized captions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: /content/gdrive/My Drive/Saumya/birds/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: /content/gdrive/My Drive/Saumya/birds/birds/test/filenames.pickle (2933)\n",
            "Load from:  /content/gdrive/My Drive/Saumya/birds/birds/captions.pickle\n",
            "Load text encoder from: /content/gdrive/My Drive/Saumya/output/text_encoder200.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75db773625a54ab3bb793e9e581db847",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: /content/gdrive/My Drive/Saumya/output/image_encoder200.pth\n",
            "Load G from:  /content/gdrive/My Drive/Saumya/output/Model/bird_AttnGAN2.pth\n",
            "cnt:  10\n",
            "cnt:  1010\n",
            "cnt:  2010\n",
            "cnt:  2940\n",
            "cnt:  3940\n",
            "cnt:  4940\n",
            "cnt:  5870\n",
            "cnt:  6870\n",
            "cnt:  7870\n",
            "cnt:  8800\n",
            "cnt:  9800\n",
            "cnt:  10800\n",
            "cnt:  11730\n",
            "cnt:  12730\n",
            "cnt:  13730\n",
            "cnt:  14660\n",
            "cnt:  15660\n",
            "cnt:  16660\n",
            "cnt:  17590\n",
            "cnt:  18590\n",
            "cnt:  19590\n",
            "cnt:  20520\n",
            "cnt:  21520\n",
            "cnt:  22520\n",
            "cnt:  23450\n",
            "cnt:  24450\n",
            "cnt:  25450\n",
            "cnt:  26380\n",
            "cnt:  27380\n",
            "cnt:  28380\n",
            "cnt:  29310\n",
            "R mean:0.6691 std:0.0092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsQ_xYd9lOG3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "154adcad-74dc-4a09-a00f-159951d95c04"
      },
      "source": [
        "!pip install scikit-fuzzy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-fuzzy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/f0/5eb5dbe0fd8dfe7d4651a8f4e591a196623a22b9e5339101e559695b4f6c/scikit-fuzzy-0.4.2.tar.gz (993kB)\n",
            "\r\u001b[K     |▎                               | 10kB 28.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 7.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 5.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 5.9MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 5.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 5.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 317kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 327kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 337kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 348kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 358kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 368kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 378kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 389kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 399kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 409kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 419kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 430kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 440kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 450kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 460kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 471kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 481kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 491kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 501kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 512kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 522kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 532kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 542kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 552kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 563kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 573kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 583kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 593kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 604kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 614kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 624kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 634kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 645kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 655kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 665kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 675kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 686kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 696kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 706kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 716kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 727kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 737kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 747kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 757kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 768kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 778kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 788kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 798kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 808kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 819kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 829kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 839kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 849kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 860kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 870kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 880kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 890kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 901kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 911kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 921kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 931kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 942kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 952kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 962kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 972kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 983kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from scikit-fuzzy) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from scikit-fuzzy) (1.4.1)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from scikit-fuzzy) (2.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.9.0->scikit-fuzzy) (4.4.2)\n",
            "Building wheels for collected packages: scikit-fuzzy\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-fuzzy: filename=scikit_fuzzy-0.4.2-cp36-none-any.whl size=894070 sha256=9ff9acef2a7ea95e101b94b49529fb2a8eb0d14ba3f695a67c7e968b61b7c4a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/4e/77/da79b16f64ef1738d95486e2731eea09d73e90a72465096600\n",
            "Successfully built scikit-fuzzy\n",
            "Installing collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J00NMM78l3ki"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "from numpy import linalg\n",
        "from numpy.linalg import norm\n",
        "from scipy.spatial.distance import squareform, pdist\n",
        "\n",
        "# Importing sklearn and TSNE.\n",
        "import sklearn\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "# We'll hack a bit with the t-SNE code in sklearn.\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.manifold.t_sne import (_joint_probabilities,\n",
        "                                    _kl_divergence)\n",
        "#from sklearn.utils.extmath import _ravel\n",
        "# Random state we define this random state to use this value in TSNE which is a randmized algo.\n",
        "RS = 25111993\n",
        "\n",
        "# Importing matplotlib for graphics.\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as PathEffects\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi2PjVtWl7FD"
      },
      "source": [
        "r=[]\n",
        "f=[]\n",
        "for i in range(len(real_imgs)):\n",
        "  r.append(real_imgs[i].cpu().detach().numpy())\n",
        "  f.append(fake_images[i].cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjWDCKJOl-G0"
      },
      "source": [
        "r=np.array(r)\n",
        "r=r.reshape(3000,10*256)\n",
        "f=np.array(f)\n",
        "f=f.reshape(3000,10*256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oenK4SZvmCwf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3a19b09-e386-4ddf-bc1c-5c660c269507"
      },
      "source": [
        "print(r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 10, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLhPfC8flWqv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a3b4727b-5f5d-4e81-e551-48916b635c1b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import skfuzzy as fuzz\n",
        "cntr, u_orig, _, _, _, _, _ = fuzz.cluster.cmeans(f-r, 2, 2, error=0.005, maxiter=1000)\n",
        "\n",
        "# Show 3-cluster model\n",
        "fig2,ax2 = plt.subplots()\n",
        "for j in range(2):\n",
        "    ax2.plot(f[0, u_orig.argmax(axis=0) == j],\n",
        "             f[1, u_orig.argmax(axis=0) == j],'o',\n",
        "             label='series ' + str(j))\n",
        "ax2.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0236596da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFBImRhFmWMq"
      },
      "source": [
        "TSNE_1 = TSNE(perplexity=600.0,).fit_transform(r)\n",
        "TSNE_2 = TSNE(perplexity=600.0,).fit_transform(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x54-2U5ilZs0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4ec4a4b3-62e9-4ccc-c981-44be123154cc"
      },
      "source": [
        "cntr, u_orig, _, _, _, _, _ = fuzz.cluster.cmeans(TSNE_1-TSNE_2, 2, 2, error=0.005, maxiter=1000)\n",
        "\n",
        "# Show 3-cluster model\n",
        "fig2,ax2 = plt.subplots()\n",
        "for j in range(2):\n",
        "    ax2.plot(TSNE_2[0, u_orig.argmax(axis=0) == j],\n",
        "             TSNE_2[1, u_orig.argmax(axis=0) == j],'o',\n",
        "             label='series ' + str(j))\n",
        "ax2.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0234676198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x4I4kF_lc_3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dc8ac4df-d3ce-4018-bc25-6d9dc39497ce"
      },
      "source": [
        "fig,ax = plt.subplots()\n",
        "for j in range(2):\n",
        "    ax.plot(TSNE_1,\n",
        "             TSNE_2,'o',\n",
        "             label='series ' + str(j))\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f02359656a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a68QBWgnlfwr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "332dd918-7fb7-4759-a700-adf56b694763"
      },
      "source": [
        "cntr, u_orig, _, _, _, _, _ = fuzz.cluster.cmeans(f-r, 2, 2, error=0.005, maxiter=1000)\n",
        "fig,ax = plt.subplots()\n",
        "for j in range(3):\n",
        "    ax.plot(f[0, u_orig.argmax(axis=0) == j],\n",
        "             f[1, u_orig.argmax(axis=0) == j],TSNE_1,'o',\n",
        "             label='series ' + str(j))\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0234513d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq9bUC63jvMa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "6259d479-bba8-41d5-93c0-5d2c36ef4da3"
      },
      "source": [
        "from math import floor\n",
        "from numpy import ones\n",
        "from numpy import expand_dims\n",
        "from numpy import log\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import exp\n",
        "from numpy.random import shuffle\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets import cifar10\n",
        "from skimage.transform import resize\n",
        "from numpy import asarray\n",
        "\n",
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        "\n",
        "# assumes images have any shape and pixels in [0,255]\n",
        "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
        "\t# load inception v3 model\n",
        "\tmodel = InceptionV3()\n",
        "\t# enumerate splits of images/predictions\n",
        "\tscores = list()\n",
        "\tn_part = floor(images.shape[0] / n_split)\n",
        "\tfor i in range(n_split):\n",
        "\t\t# retrieve images\n",
        "\t\tix_start, ix_end = i * n_part, (i+1) * n_part\n",
        "\t\tsubset = images[ix_start:ix_end]\n",
        "\t\t# convert from uint8 to float32\n",
        "\t\tsubset = subset.astype('float32')\n",
        "\t\t# scale images to the required size\n",
        "\t\tsubset = scale_images(subset, (299,299,3))\n",
        "\t\t# pre-process images, scale to [-1,1]\n",
        "\t\tsubset = preprocess_input(subset)\n",
        "\t\t# predict p(y|x)\n",
        "\t\tp_yx = model.predict(subset)\n",
        "\t\t# calculate p(y)\n",
        "\t\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
        "\t\t# calculate KL divergence using log probabilities\n",
        "\t\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
        "\t\t# sum over classes\n",
        "\t\tsum_kl_d = kl_d.sum(axis=1)\n",
        "\t\t# average over images\n",
        "\t\tavg_kl_d = mean(sum_kl_d)\n",
        "\t\t# undo the log\n",
        "\t\tis_score = exp(avg_kl_d)\n",
        "\t\t# store\n",
        "\t\tscores.append(is_score)\n",
        "\t# average across images\n",
        "\tis_avg, is_std = mean(scores), std(scores)\n",
        "\treturn is_avg, is_std\n",
        "\n",
        "#dataloader\n",
        "imsize = BASE_SIZE * (2 ** (BRANCH_NUM - 1))\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Scale(int(imsize * 76 / 64)),\n",
        "    transforms.RandomCrop(imsize),\n",
        "    transforms.RandomHorizontalFlip()])\n",
        "split_dir='test'\n",
        "dataset = TextDataset(DATA_DIR, split_dir,\n",
        "                      base_size=BASE_SIZE,\n",
        "                      transform=image_transform)\n",
        "assert dataset\n",
        "# generate fake images\n",
        "fimgs=[]\n",
        "if NET_G == '':\n",
        "            print('Error: the path for morels is not found!')\n",
        "else:\n",
        "    if split_dir == 'test':\n",
        "        split_dir = 'valid'\n",
        "    # Build /:and load the generator\n",
        "    if B_DCGAN:\n",
        "        netG = G_DCGAN()\n",
        "    else:\n",
        "        netG = G_NET()\n",
        "    netG.apply(weights_init)\n",
        "    netG.cuda()\n",
        "    netG.eval()\n",
        "\n",
        "    # load text encoder\n",
        "    text_encoder = RNN_ENCODER(dataset.n_words, nhidden=EMBEDDING_DIM)\n",
        "    state_dict = torch.load(NET_E, map_location=lambda storage, loc: storage)\n",
        "    text_encoder.load_state_dict(state_dict)\n",
        "    print('Load text encoder from:', NET_E)\n",
        "    text_encoder = text_encoder.cuda()\n",
        "    text_encoder.eval()\n",
        "\n",
        "    #load image encoder\n",
        "    image_encoder = CNN_ENCODER(EMBEDDING_DIM)\n",
        "    img_encoder_path = NET_E.replace('text_encoder', 'image_encoder')\n",
        "    state_dict = torch.load(img_encoder_path, map_location=lambda storage, loc: storage)\n",
        "    image_encoder.load_state_dict(state_dict)\n",
        "    print('Load image encoder from:', img_encoder_path)\n",
        "    image_encoder = image_encoder.cuda()\n",
        "    image_encoder.eval()\n",
        "\n",
        "    batch_size = 10\n",
        "    nz = 100\n",
        "    noise = Variable(torch.FloatTensor(batch_size, nz), volatile=True)\n",
        "    noise = noise.cuda()\n",
        "\n",
        "    model_dir = NET_G\n",
        "    state_dict = torch.load(model_dir, map_location=lambda storage, loc: storage)\n",
        "    # state_dict = torch.load(NET_G)\n",
        "    netG.load_state_dict(state_dict)\n",
        "    print('Load G from: ', model_dir)\n",
        "    bshuffle=True\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=BATCH_SIZE,\n",
        "    drop_last=True, shuffle=bshuffle, num_workers=int(WORKERS))\n",
        "    cnt = 0\n",
        "    cont = True\n",
        "    for ii in range(11):  # (CAPTIONS_PER_IMAGE):\n",
        "        if (cont == False):\n",
        "            break\n",
        "        for step, data in enumerate(data_loader, 0):\n",
        "            cnt += batch_size\n",
        "            if (cont == False):\n",
        "                break\n",
        "            if step % 100 == 0:\n",
        "                print('cnt: ', cnt)\n",
        "\n",
        "            imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
        "            hidden = text_encoder.init_hidden(batch_size)\n",
        "            words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
        "            words_embs, sent_emb = words_embs.detach(), sent_emb.detach()\n",
        "            mask = (captions == 0)\n",
        "            num_words = words_embs.size(2)\n",
        "            if mask.size(1) > num_words:\n",
        "                mask = mask[:, :num_words]\n",
        "            mask = (captions == 0)\n",
        "            num_words = words_embs.size(2)\n",
        "            if mask.size(1) > num_words:\n",
        "                mask = mask[:, :num_words]\n",
        "            noise.data.normal_(0, 1)\n",
        "            fake_imgs, _, mu, logvar = netG(noise, sent_emb, words_embs, mask)\n",
        "            for j in range(batch_size):\n",
        "                k = -1\n",
        "                im = fake_imgs[k][j].data.cpu().numpy()\n",
        "                im = (im + 1.0) * 127.5\n",
        "                im = im.astype(np.uint8)\n",
        "                im = np.transpose(im, (1, 2, 0))\n",
        "                fimgs.append(im)\n",
        "               \n",
        "                        \n",
        "fimgs=np.array(fimgs)\n",
        "shuffle(fimgs)\n",
        "is_avg, is_std = calculate_inception_score(fimgs)\n",
        "print('score', is_avg, is_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: /content/gdrive/My Drive/Saumya/birds/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: /content/gdrive/My Drive/Saumya/birds/birds/test/filenames.pickle (2933)\n",
            "Load from:  /content/gdrive/My Drive/Saumya/birds/birds/captions.pickle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:123: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Load text encoder from: /content/gdrive/My Drive/Saumya/output/text_encoder200.pth\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: /content/gdrive/My Drive/Saumya/output/image_encoder200.pth\n",
            "Load G from:  /content/gdrive/My Drive/Saumya/output/Model/bird_AttnGAN2.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:106: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnt:  10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:460: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnt:  1010\n",
            "cnt:  2010\n",
            "cnt:  2940\n",
            "cnt:  3940\n",
            "cnt:  4940\n",
            "cnt:  5870\n",
            "cnt:  6870\n",
            "cnt:  7870\n",
            "cnt:  8800\n",
            "cnt:  9800\n",
            "cnt:  10800\n",
            "cnt:  11730\n",
            "cnt:  12730\n",
            "cnt:  13730\n",
            "cnt:  14660\n",
            "cnt:  15660\n",
            "cnt:  16660\n",
            "cnt:  17590\n",
            "cnt:  18590\n",
            "cnt:  19590\n",
            "cnt:  20520\n",
            "cnt:  21520\n",
            "cnt:  22520\n",
            "cnt:  23450\n",
            "cnt:  24450\n",
            "cnt:  25450\n",
            "cnt:  26380\n",
            "cnt:  27380\n",
            "cnt:  28380\n",
            "cnt:  29310\n",
            "cnt:  30310\n",
            "cnt:  31310\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "score 5.3820662 0.08969117\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}